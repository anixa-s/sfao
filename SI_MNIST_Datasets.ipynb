{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856d42ce-4fcc-4348-ba68-fd679cd71a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/ContinualAI/continual-learning-baselines.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38bdc453-c43e-40d8-b960-be4e2f3d9792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (25.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch==2.1.2 in /usr/local/lib/python3.10/dist-packages (2.1.2+cu118)\n",
      "Requirement already satisfied: torchvision==0.16.2 in /usr/local/lib/python3.10/dist-packages (0.16.2+cu118)\n",
      "Requirement already satisfied: torchaudio==2.1.2 in /usr/local/lib/python3.10/dist-packages (2.1.2+cu118)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2) (4.15.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2) (2023.4.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2) (2.1.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.16.2) (1.26.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.16.2) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.16.2) (9.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.2) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.16.2) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.16.2) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.16.2) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.16.2) (2022.12.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.2) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: avalanche-lib==0.6.0 in /usr/local/lib/python3.10/dist-packages (0.6.0)\n",
      "Requirement already satisfied: matplotlib==3.10.5 in /usr/local/lib/python3.10/dist-packages (3.10.5)\n",
      "Requirement already satisfied: numpy==1.26.1 in /usr/local/lib/python3.10/dist-packages (1.26.1)\n",
      "Requirement already satisfied: tqdm==4.67.1 in /usr/local/lib/python3.10/dist-packages (4.67.1)\n",
      "Requirement already satisfied: kornia==0.8.1 in /usr/local/lib/python3.10/dist-packages (0.8.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from avalanche-lib==0.6.0) (4.15.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from avalanche-lib==0.6.0) (5.9.6)\n",
      "Requirement already satisfied: gputil in /usr/local/lib/python3.10/dist-packages (from avalanche-lib==0.6.0) (1.4.0)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from avalanche-lib==0.6.0) (1.7.1)\n",
      "Requirement already satisfied: pytorchcv in /usr/local/lib/python3.10/dist-packages (from avalanche-lib==0.6.0) (0.0.73)\n",
      "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (from avalanche-lib==0.6.0) (0.21.1)\n",
      "Requirement already satisfied: tensorboard>=1.15 in /usr/local/lib/python3.10/dist-packages (from avalanche-lib==0.6.0) (2.20.0)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from avalanche-lib==0.6.0) (2.1.2+cu118)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from avalanche-lib==0.6.0) (0.16.2+cu118)\n",
      "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.10/dist-packages (from avalanche-lib==0.6.0) (0.11.4)\n",
      "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (from avalanche-lib==0.6.0) (5.2.0)\n",
      "Requirement already satisfied: qpsolvers[open_source_solvers] in /usr/local/lib/python3.10/dist-packages (from avalanche-lib==0.6.0) (4.8.1)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from avalanche-lib==0.6.0) (0.4.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from avalanche-lib==0.6.0) (25.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.10.5) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.10.5) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.10.5) (4.59.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.10.5) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.10.5) (9.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib==3.10.5) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.10.5) (2.8.2)\n",
      "Requirement already satisfied: kornia_rs>=0.1.9 in /usr/local/lib/python3.10/dist-packages (from kornia==0.8.1) (0.1.9)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib==3.10.5) (1.16.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=1.15->avalanche-lib==0.6.0) (2.3.1)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=1.15->avalanche-lib==0.6.0) (1.74.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=1.15->avalanche-lib==0.6.0) (3.8.2)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=1.15->avalanche-lib==0.6.0) (6.32.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=1.15->avalanche-lib==0.6.0) (68.2.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=1.15->avalanche-lib==0.6.0) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=1.15->avalanche-lib==0.6.0) (3.1.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->avalanche-lib==0.6.0) (3.9.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->avalanche-lib==0.6.0) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->avalanche-lib==0.6.0) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->avalanche-lib==0.6.0) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->avalanche-lib==0.6.0) (2023.4.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->avalanche-lib==0.6.0) (2.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=1.15->avalanche-lib==0.6.0) (2.1.2)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown->avalanche-lib==0.6.0) (4.12.2)\n",
      "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown->avalanche-lib==0.6.0) (2.31.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown->avalanche-lib==0.6.0) (2.5)\n",
      "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from qpsolvers[open_source_solvers]->avalanche-lib==0.6.0) (1.15.3)\n",
      "Requirement already satisfied: qpax>=0.0.9 in /usr/local/lib/python3.10/dist-packages (from qpsolvers[open_source_solvers]->avalanche-lib==0.6.0) (0.0.9)\n",
      "Requirement already satisfied: jaxopt>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from qpsolvers[open_source_solvers]->avalanche-lib==0.6.0) (0.8.5)\n",
      "Requirement already satisfied: ecos>=2.0.8 in /usr/local/lib/python3.10/dist-packages (from qpsolvers[open_source_solvers]->avalanche-lib==0.6.0) (2.0.14)\n",
      "Requirement already satisfied: osqp>=0.6.2 in /usr/local/lib/python3.10/dist-packages (from qpsolvers[open_source_solvers]->avalanche-lib==0.6.0) (1.0.4)\n",
      "Requirement already satisfied: clarabel>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from qpsolvers[open_source_solvers]->avalanche-lib==0.6.0) (0.11.1)\n",
      "Requirement already satisfied: proxsuite>=0.2.9 in /usr/local/lib/python3.10/dist-packages (from qpsolvers[open_source_solvers]->avalanche-lib==0.6.0) (0.7.2)\n",
      "Requirement already satisfied: cvxopt>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from qpsolvers[open_source_solvers]->avalanche-lib==0.6.0) (1.3.2)\n",
      "Requirement already satisfied: sip-python>=0.0.2 in /usr/local/lib/python3.10/dist-packages (from qpsolvers[open_source_solvers]->avalanche-lib==0.6.0) (0.0.2)\n",
      "Requirement already satisfied: qpalm>=1.2.1 in /usr/local/lib/python3.10/dist-packages (from qpsolvers[open_source_solvers]->avalanche-lib==0.6.0) (1.2.5)\n",
      "Requirement already satisfied: daqp>=0.5.1 in /usr/local/lib/python3.10/dist-packages (from qpsolvers[open_source_solvers]->avalanche-lib==0.6.0) (0.7.2)\n",
      "Requirement already satisfied: highspy>=1.1.2.dev3 in /usr/local/lib/python3.10/dist-packages (from qpsolvers[open_source_solvers]->avalanche-lib==0.6.0) (1.11.0)\n",
      "Requirement already satisfied: piqp>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from qpsolvers[open_source_solvers]->avalanche-lib==0.6.0) (0.6.1)\n",
      "Requirement already satisfied: quadprog>=0.1.11 in /usr/local/lib/python3.10/dist-packages (from qpsolvers[open_source_solvers]->avalanche-lib==0.6.0) (0.1.13)\n",
      "Requirement already satisfied: scs>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from qpsolvers[open_source_solvers]->avalanche-lib==0.6.0) (3.2.8)\n",
      "Requirement already satisfied: cffi in /usr/local/lib/python3.10/dist-packages (from clarabel>=0.4.1->qpsolvers[open_source_solvers]->avalanche-lib==0.6.0) (1.16.0)\n",
      "Requirement already satisfied: jax>=0.2.18 in /usr/local/lib/python3.10/dist-packages (from jaxopt>=0.8.3->qpsolvers[open_source_solvers]->avalanche-lib==0.6.0) (0.6.2)\n",
      "Requirement already satisfied: jaxlib>=0.1.69 in /usr/local/lib/python3.10/dist-packages (from jaxopt>=0.8.3->qpsolvers[open_source_solvers]->avalanche-lib==0.6.0) (0.6.2)\n",
      "Requirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.2.18->jaxopt>=0.8.3->qpsolvers[open_source_solvers]->avalanche-lib==0.6.0) (0.5.3)\n",
      "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.10/dist-packages (from jax>=0.2.18->jaxopt>=0.8.3->qpsolvers[open_source_solvers]->avalanche-lib==0.6.0) (3.4.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from osqp>=0.6.2->qpsolvers[open_source_solvers]->avalanche-lib==0.6.0) (1.5.2)\n",
      "Requirement already satisfied: cmeel in /usr/local/lib/python3.10/dist-packages (from proxsuite>=0.2.9->qpsolvers[open_source_solvers]->avalanche-lib==0.6.0) (0.57.3)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi->clarabel>=0.4.1->qpsolvers[open_source_solvers]->avalanche-lib==0.6.0) (2.21)\n",
      "Requirement already satisfied: tomli>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from cmeel->proxsuite>=0.2.9->qpsolvers[open_source_solvers]->avalanche-lib==0.6.0) (2.2.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown->avalanche-lib==0.6.0) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown->avalanche-lib==0.6.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown->avalanche-lib==0.6.0) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown->avalanche-lib==0.6.0) (2022.12.7)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown->avalanche-lib==0.6.0) (1.7.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->avalanche-lib==0.6.0) (3.6.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->avalanche-lib==0.6.0) (1.3.0)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb->avalanche-lib==0.6.0) (8.2.1)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->avalanche-lib==0.6.0) (3.1.45)\n",
      "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb->avalanche-lib==0.6.0) (3.11.0)\n",
      "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.10/dist-packages (from wandb->avalanche-lib==0.6.0) (2.11.7)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb->avalanche-lib==0.6.0) (6.0.1)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->avalanche-lib==0.6.0) (2.35.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3->wandb->avalanche-lib==0.6.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3->wandb->avalanche-lib==0.6.0) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3->wandb->avalanche-lib==0.6.0) (0.4.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->avalanche-lib==0.6.0) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->avalanche-lib==0.6.0) (5.0.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: torchmetrics==0.11.4 in /usr/local/lib/python3.10/dist-packages (0.11.4)\n",
      "Requirement already satisfied: lightning-utilities==0.10.0 in /usr/local/lib/python3.10/dist-packages (0.10.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (25.0)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from torchmetrics==0.11.4) (1.26.1)\n",
      "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics==0.11.4) (2.1.2+cu118)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities==0.10.0) (68.2.2)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities==0.10.0) (4.15.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics==0.11.4) (3.9.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics==0.11.4) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics==0.11.4) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics==0.11.4) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics==0.11.4) (2023.4.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics==0.11.4) (2.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.1->torchmetrics==0.11.4) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.1->torchmetrics==0.11.4) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Upgrade pip first\n",
    "!python -m pip install --upgrade pip\n",
    "\n",
    "# Core dependencies\n",
    "!pip install torch==2.1.2 torchvision==0.16.2 torchaudio==2.1.2 --extra-index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install avalanche-lib==0.6.0 matplotlib==3.10.5 numpy==1.26.1 tqdm==4.67.1 kornia==0.8.1\n",
    "!pip install torchmetrics==0.11.4 lightning-utilities==0.10.0 packaging --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "feacdaf4-0d2b-46a0-9231-bbb29c22d041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requirements\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a9a6671-85f0-4011-b89f-21e26bdd854c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/avalanche/training/plugins/evaluation.py:94: UserWarning: No loggers specified, metrics will not be logged\n",
      "  warnings.warn(\"No loggers specified, metrics will not be logged\")\n"
     ]
    }
   ],
   "source": [
    "# Old import\n",
    "# from avalanche.evaluation import metric_helpers as mh\n",
    "\n",
    "# New Avalanche 0.6+ way:\n",
    "from avalanche.evaluation.metrics import accuracy_metrics, loss_metrics\n",
    "from avalanche.training.plugins import EvaluationPlugin\n",
    "\n",
    "# Example:\n",
    "eval_plugin = EvaluationPlugin(\n",
    "    accuracy_metrics(minibatch=False, epoch=True),\n",
    "    loss_metrics(minibatch=False, epoch=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43f68cbf-82c1-4b7b-a22a-4cdff3927af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avalanche evaluation plugin created successfully!\n"
     ]
    }
   ],
   "source": [
    "# As a test to see if the plugin works \n",
    "from avalanche.training.plugins import EvaluationPlugin\n",
    "from avalanche.evaluation.metrics import accuracy_metrics, loss_metrics\n",
    "\n",
    "# Create a simple evaluation plugin\n",
    "eval_plugin = EvaluationPlugin(\n",
    "    accuracy_metrics(minibatch=False, epoch=True),\n",
    "    loss_metrics(minibatch=False, epoch=True)\n",
    ")\n",
    "\n",
    "print(\"Avalanche evaluation plugin created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b523d30-e6be-4723-8897-3d9f50831360",
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments.split_mnist import synaptic_intelligence_smnist\n",
    "from avalanche.evaluation import metrics\n",
    "from avalanche.training.plugins import EvaluationPlugin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9766667f-d9b2-4286-98cf-493c347e220b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import torch\n",
    "\n",
    "# To calculate memory in MB\n",
    "def get_model_size_mb(model):\n",
    "    \"\"\"Compute memory usage of a PyTorch model in megabytes.\"\"\"\n",
    "    param_size = 0\n",
    "    for param in model.parameters():\n",
    "        param_size += param.nelement() * param.element_size()  # bytes\n",
    "    return param_size / (1024 ** 2)  # convert to MB\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb523137-dc82-42be-936c-68f2cb6ba30a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to /root/.avalanche/data/mnist/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:00<00:00, 80409304.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /root/.avalanche/data/mnist/MNIST/raw/train-images-idx3-ubyte.gz to /root/.avalanche/data/mnist/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to /root/.avalanche/data/mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 2748523.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /root/.avalanche/data/mnist/MNIST/raw/train-labels-idx1-ubyte.gz to /root/.avalanche/data/mnist/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to /root/.avalanche/data/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 19631913.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /root/.avalanche/data/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz to /root/.avalanche/data/mnist/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to /root/.avalanche/data/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 6125571.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /root/.avalanche/data/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to /root/.avalanche/data/mnist/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/avalanche/training/templates/base.py:468: PositionalArgumentsDeprecatedWarning: Avalanche is transitioning to strategy constructors that accept named (keyword) arguments only. This is done to ensure that there is no confusion regarding the meaning of each argument (strategies can have many arguments). Your are passing 3 positional arguments to the SynapticIntelligence.__init__ method. Consider passing them as names arguments. The ability to pass positional arguments will be removed in the future.\n",
      "  warnings.warn(error_str, category=PositionalArgumentsDeprecatedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- >> Start of training phase << --\n",
      "100%|██████████| 396/396 [00:28<00:00, 13.68it/s]\n",
      "Epoch 0 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9916\n",
      "100%|██████████| 396/396 [00:29<00:00, 13.57it/s]\n",
      "Epoch 1 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9979\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 17/17 [00:01<00:00, 15.31it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.9991\n",
      "-- Starting eval on experience 1 (Task 1) from test stream --\n",
      "100%|██████████| 16/16 [00:01<00:00, 14.35it/s]\n",
      "> Eval on experience 1 (Task 1) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task001/Exp001 = 0.0000\n",
      "-- Starting eval on experience 2 (Task 2) from test stream --\n",
      "100%|██████████| 15/15 [00:00<00:00, 16.54it/s]\n",
      "> Eval on experience 2 (Task 2) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task002/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 3) from test stream --\n",
      "100%|██████████| 16/16 [00:01<00:00, 15.81it/s]\n",
      "> Eval on experience 3 (Task 3) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task003/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 4) from test stream --\n",
      "100%|██████████| 16/16 [00:01<00:00, 15.95it/s]\n",
      "> Eval on experience 4 (Task 4) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task004/Exp004 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task004 = 0.2113\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 378/378 [00:32<00:00, 11.78it/s]\n",
      "Epoch 0 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task001 = 0.9426\n",
      "100%|██████████| 378/378 [00:31<00:00, 12.11it/s]\n",
      "Epoch 1 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task001 = 0.9723\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 17/17 [00:01<00:00, 15.28it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.9962\n",
      "-- Starting eval on experience 1 (Task 1) from test stream --\n",
      "100%|██████████| 16/16 [00:01<00:00, 14.45it/s]\n",
      "> Eval on experience 1 (Task 1) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task001/Exp001 = 0.9775\n",
      "-- Starting eval on experience 2 (Task 2) from test stream --\n",
      "100%|██████████| 15/15 [00:00<00:00, 15.03it/s]\n",
      "> Eval on experience 2 (Task 2) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task002/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 3) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 16.03it/s]\n",
      "> Eval on experience 3 (Task 3) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task003/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 4) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 17.76it/s]\n",
      "> Eval on experience 4 (Task 4) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task004/Exp004 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task004 = 0.4103\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 352/352 [00:29<00:00, 12.05it/s]\n",
      "Epoch 0 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task002 = 0.9458\n",
      "100%|██████████| 352/352 [00:29<00:00, 12.05it/s]\n",
      "Epoch 1 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task002 = 0.9884\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 17/17 [00:01<00:00, 15.35it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.9962\n",
      "-- Starting eval on experience 1 (Task 1) from test stream --\n",
      "100%|██████████| 16/16 [00:01<00:00, 13.25it/s]\n",
      "> Eval on experience 1 (Task 1) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task001/Exp001 = 0.9432\n",
      "-- Starting eval on experience 2 (Task 2) from test stream --\n",
      "100%|██████████| 15/15 [00:01<00:00, 14.94it/s]\n",
      "> Eval on experience 2 (Task 2) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task002/Exp002 = 0.9920\n",
      "-- Starting eval on experience 3 (Task 3) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 16.11it/s]\n",
      "> Eval on experience 3 (Task 3) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task003/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 4) from test stream --\n",
      "100%|██████████| 16/16 [00:00<00:00, 17.22it/s]\n",
      "> Eval on experience 4 (Task 4) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task004/Exp004 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task004 = 0.5892\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 381/381 [00:32<00:00, 11.84it/s]\n",
      "Epoch 0 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task003 = 0.9761\n",
      "100%|██████████| 381/381 [00:31<00:00, 12.17it/s]\n",
      "Epoch 1 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task003 = 0.9980\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 17/17 [00:01<00:00, 15.19it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.9929\n",
      "-- Starting eval on experience 1 (Task 1) from test stream --\n",
      "100%|██████████| 16/16 [00:01<00:00, 14.60it/s]\n",
      "> Eval on experience 1 (Task 1) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task001/Exp001 = 0.9510\n",
      "-- Starting eval on experience 2 (Task 2) from test stream --\n",
      "100%|██████████| 15/15 [00:00<00:00, 16.96it/s]\n",
      "> Eval on experience 2 (Task 2) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task002/Exp002 = 0.9888\n",
      "-- Starting eval on experience 3 (Task 3) from test stream --\n",
      "100%|██████████| 16/16 [00:01<00:00, 14.77it/s]\n",
      "> Eval on experience 3 (Task 3) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task003/Exp003 = 0.9950\n",
      "-- Starting eval on experience 4 (Task 4) from test stream --\n",
      "100%|██████████| 16/16 [00:01<00:00, 15.89it/s]\n",
      "> Eval on experience 4 (Task 4) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task004/Exp004 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task004 = 0.7871\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 369/369 [00:30<00:00, 12.19it/s]\n",
      "Epoch 0 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task004 = 0.9558\n",
      "100%|██████████| 369/369 [00:29<00:00, 12.51it/s]\n",
      "Epoch 1 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task004 = 0.9789\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 17/17 [00:01<00:00, 14.00it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.9929\n",
      "-- Starting eval on experience 1 (Task 1) from test stream --\n",
      "100%|██████████| 16/16 [00:01<00:00, 13.36it/s]\n",
      "> Eval on experience 1 (Task 1) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task001/Exp001 = 0.9427\n",
      "-- Starting eval on experience 2 (Task 2) from test stream --\n",
      "100%|██████████| 15/15 [00:00<00:00, 15.04it/s]\n",
      "> Eval on experience 2 (Task 2) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task002/Exp002 = 0.9824\n",
      "-- Starting eval on experience 3 (Task 3) from test stream --\n",
      "100%|██████████| 16/16 [00:01<00:00, 15.85it/s]\n",
      "> Eval on experience 3 (Task 3) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task003/Exp003 = 0.9879\n",
      "-- Starting eval on experience 4 (Task 4) from test stream --\n",
      "100%|██████████| 16/16 [00:01<00:00, 13.52it/s]\n",
      "> Eval on experience 4 (Task 4) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task004/Exp004 = 0.9778\n",
      "-- >> End of eval phase << --\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task004 = 0.9767\n",
      "Keys in result: dict_keys(['Top1_Acc_Epoch/train_phase/train_stream/Task000', 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000', 'Top1_Acc_Exp/eval_phase/test_stream/Task001/Exp001', 'Top1_Acc_Exp/eval_phase/test_stream/Task002/Exp002', 'Top1_Acc_Exp/eval_phase/test_stream/Task003/Exp003', 'Top1_Acc_Exp/eval_phase/test_stream/Task004/Exp004', 'Top1_Acc_Stream/eval_phase/test_stream/Task004', 'Top1_Acc_Epoch/train_phase/train_stream/Task001', 'Top1_Acc_Epoch/train_phase/train_stream/Task002', 'Top1_Acc_Epoch/train_phase/train_stream/Task003', 'Top1_Acc_Epoch/train_phase/train_stream/Task004'])\n",
      "Accuracy matrix shape: (11,)\n",
      "Accuracy matrix:\n",
      " [0.9979471  0.9929078  0.94270323 0.98239061 0.98791541 0.9778114\n",
      " 0.9767     0.97228886 0.988369   0.99803004 0.97889831]\n",
      "ACC: 0.9788983050847457\n",
      "F: 0.01913173677686475\n",
      "FWT (approx.): 0.9817063440226896\n",
      "BWT: -0.0028080389379437575\n",
      "PSM: 0.9808305001108197\n"
     ]
    }
   ],
   "source": [
    "# Run SI on Split MNIST\n",
    "res = synaptic_intelligence_smnist(\n",
    "    override_args={'epochs': 2}  # faster for CPU\n",
    ")\n",
    "\n",
    "# Inspect top-level keys\n",
    "print(\"Keys in result:\", res.keys())\n",
    "\n",
    "# If metric values are nested, find them dynamically\n",
    "accuracy_matrix = []\n",
    "for key in res:\n",
    "    if 'Top1_Acc' in key:  # adjust if needed\n",
    "        accuracy_matrix.append(res[key])\n",
    "\n",
    "accuracy_matrix = np.array(accuracy_matrix)\n",
    "print(\"Accuracy matrix shape:\", accuracy_matrix.shape)\n",
    "print(\"Accuracy matrix:\\n\", accuracy_matrix)\n",
    "\n",
    "# Compute CL metrics \n",
    "ACC = accuracy_matrix[-1]\n",
    "F = np.mean(np.max(accuracy_matrix[:-1]) - accuracy_matrix[-1])  # forgetting\n",
    "\n",
    "# Approximate FWT\n",
    "FWT = np.mean(accuracy_matrix[:-1])\n",
    "\n",
    "# Compute BWT\n",
    "BWT = np.mean(accuracy_matrix[-1] - accuracy_matrix[:-1])\n",
    "\n",
    "PSM = ACC / (ACC + abs(F))\n",
    "\n",
    "# Memory usage (MB)\n",
    "# memory_mb = get_model_size_mb(si_model)  # use your real model, not res['model']\n",
    "# print(\"Memory usage (MB):\", memory_mb)\n",
    "\n",
    "print(\"ACC:\", ACC)\n",
    "print(\"F:\", F)\n",
    "print(\"FWT (approx.):\", FWT)\n",
    "print(\"BWT:\", BWT)\n",
    "print(\"PSM:\", PSM)\n",
    "# print(\"Memory usage (MB):\", memory_mb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89d5db40-1a27-4eb3-8ebe-09699ee6bfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments.permuted_mnist import synaptic_intelligence_pmnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "311c5cd8-e4cf-40c5-b07e-98077036381e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to /root/.avalanche/data/mnist/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:00<00:00, 78111218.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /root/.avalanche/data/mnist/MNIST/raw/train-images-idx3-ubyte.gz to /root/.avalanche/data/mnist/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to /root/.avalanche/data/mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 2610908.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /root/.avalanche/data/mnist/MNIST/raw/train-labels-idx1-ubyte.gz to /root/.avalanche/data/mnist/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to /root/.avalanche/data/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 19813582.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /root/.avalanche/data/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz to /root/.avalanche/data/mnist/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to /root/.avalanche/data/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 3603959.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /root/.avalanche/data/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to /root/.avalanche/data/mnist/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/avalanche/training/templates/base.py:468: PositionalArgumentsDeprecatedWarning: Avalanche is transitioning to strategy constructors that accept named (keyword) arguments only. This is done to ensure that there is no confusion regarding the meaning of each argument (strategies can have many arguments). Your are passing 3 positional arguments to the SynapticIntelligence.__init__ method. Consider passing them as names arguments. The ability to pass positional arguments will be removed in the future.\n",
      "  warnings.warn(error_str, category=PositionalArgumentsDeprecatedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- >> Start of training phase << --\n",
      "100%|██████████| 938/938 [01:22<00:00, 11.41it/s]\n",
      "Epoch 0 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8550\n",
      "100%|██████████| 938/938 [01:19<00:00, 11.86it/s]\n",
      "Epoch 1 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9185\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:06<00:00, 13.13it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.9289\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:06<00:00, 12.74it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.1016\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:06<00:00, 12.31it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.1053\n",
      "-- >> End of eval phase << --\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.3786\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 938/938 [01:17<00:00, 12.11it/s]\n",
      "Epoch 0 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8684\n",
      "100%|██████████| 938/938 [01:19<00:00, 11.74it/s]\n",
      "Epoch 1 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9247\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:06<00:00, 12.16it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.9156\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:06<00:00, 11.98it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.9351\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:06<00:00, 11.95it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.1182\n",
      "-- >> End of eval phase << --\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.6563\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 938/938 [01:17<00:00, 12.04it/s]\n",
      "Epoch 0 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8711\n",
      "100%|██████████| 938/938 [01:22<00:00, 11.33it/s]\n",
      "Epoch 1 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9289\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:05<00:00, 13.19it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.8893\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:05<00:00, 13.63it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.9137\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 79/79 [00:06<00:00, 12.32it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.9396\n",
      "-- >> End of eval phase << --\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.9142\n",
      "Keys in result: dict_keys(['Top1_Acc_Epoch/train_phase/train_stream/Task000', 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000', 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp001', 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp002', 'Top1_Acc_Stream/eval_phase/test_stream/Task000'])\n",
      "Accuracy matrix shape: (5,)\n",
      "Accuracy matrix:\n",
      " [0.92893333 0.8893     0.9137     0.9396     0.9142    ]\n",
      "ACC: 0.9142\n",
      "F: 0.025399999999999978\n",
      "FWT (approx.): 0.9178833333333333\n",
      "BWT: -0.0036833333333333163\n",
      "PSM: 0.9729672200936569\n"
     ]
    }
   ],
   "source": [
    "# Run SI on Permuted MNIST\n",
    "res = synaptic_intelligence_pmnist(override_args={'epochs': 2})\n",
    "\n",
    "# Inspect top-level keys\n",
    "print(\"Keys in result:\", res.keys())\n",
    "\n",
    "# If metric values are nested, find them dynamically\n",
    "accuracy_matrix = []\n",
    "for key in res:\n",
    "    if 'Top1_Acc' in key:  # adjust if needed\n",
    "        accuracy_matrix.append(res[key])\n",
    "\n",
    "accuracy_matrix = np.array(accuracy_matrix)\n",
    "print(\"Accuracy matrix shape:\", accuracy_matrix.shape)\n",
    "print(\"Accuracy matrix:\\n\", accuracy_matrix)\n",
    "\n",
    "# Compute CL metrics \n",
    "ACC = accuracy_matrix[-1]\n",
    "F = np.mean(np.max(accuracy_matrix[:-1]) - accuracy_matrix[-1])  # forgetting\n",
    "\n",
    "# Approximate FWT\n",
    "FWT = np.mean(accuracy_matrix[:-1])\n",
    "\n",
    "# Compute BWT\n",
    "BWT = np.mean(accuracy_matrix[-1] - accuracy_matrix[:-1])\n",
    "\n",
    "PSM = ACC / (ACC + abs(F))\n",
    "\n",
    "# Memory usage (MB)\n",
    "# memory_mb = get_model_size_mb(si_model)  # use your real model, not res['model']\n",
    "# print(\"Memory usage (MB):\", memory_mb)\n",
    "\n",
    "print(\"ACC:\", ACC)\n",
    "print(\"F:\", F)\n",
    "print(\"FWT (approx.):\", FWT)\n",
    "print(\"BWT:\", BWT)\n",
    "print(\"PSM:\", PSM)\n",
    "# print(\"Memory usage (MB):\", memory_mb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39784f2f-4f64-4fd4-8d98-43f028dc2e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function si_split_cifar100 at 0x7186455be170>\n"
     ]
    }
   ],
   "source": [
    "# Split CIFAR-100\n",
    "from experiments.si_split_cifar100 import si_split_cifar100\n",
    "print(si_split_cifar100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a625364-ee54-4c96-9adf-da58798baf88",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'si_split_cifar100' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Run SI on Split CIFAR-100\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43msi_split_cifar100\u001b[49m({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m2\u001b[39m})  \u001b[38;5;66;03m# test run\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mType of res:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mtype\u001b[39m(res))\n\u001b[1;32m      5\u001b[0m accuracy_matrix \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mNameError\u001b[0m: name 'si_split_cifar100' is not defined"
     ]
    }
   ],
   "source": [
    "# Run SI on Split CIFAR-100\n",
    "res = si_split_cifar100({'epochs': 2})  # test run\n",
    "print(\"Type of res:\", type(res))\n",
    "\n",
    "accuracy_matrix = []\n",
    "\n",
    "if isinstance(res, dict):\n",
    "    for key in res:\n",
    "        if 'Top1_Acc' in key:\n",
    "            accuracy_matrix.append(res[key])\n",
    "\n",
    "elif isinstance(res, list):\n",
    "    if len(res) > 0 and isinstance(res[0], dict):\n",
    "        # list of dicts\n",
    "        for r in res:\n",
    "            for key in r:\n",
    "                if 'Top1_Acc' in key:\n",
    "                    accuracy_matrix.append(r[key])\n",
    "    else:\n",
    "        # assume it's a list of accuracies already\n",
    "        accuracy_matrix = res\n",
    "\n",
    "accuracy_matrix = np.array(accuracy_matrix)\n",
    "print(\"Accuracy matrix shape:\", accuracy_matrix.shape)\n",
    "print(\"Accuracy matrix:\\n\", accuracy_matrix)\n",
    "\n",
    "# Compute CL metrics\n",
    "ACC = accuracy_matrix[-1]\n",
    "F = np.mean(np.max(accuracy_matrix[:-1]) - accuracy_matrix[-1])\n",
    "FWT = np.mean(accuracy_matrix[:-1])\n",
    "BWT = np.mean(accuracy_matrix[-1] - accuracy_matrix[:-1])\n",
    "PSM = ACC / (ACC + abs(F))\n",
    "\n",
    "print(\"ACC:\", ACC)\n",
    "print(\"F:\", F)\n",
    "print(\"FWT (approx.):\", FWT)\n",
    "print(\"BWT:\", BWT)\n",
    "print(\"PSM:\", PSM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "359bab3c-ecb6-4a98-98a3-963458c146b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function si_split_cifar10 at 0x7a05d436bd00>\n"
     ]
    }
   ],
   "source": [
    "# Split CIFAR-10\n",
    "from experiments.si_split_cifar10 import si_split_cifar10\n",
    "print(si_split_cifar10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2fbadabc-2c69-4976-bc12-eb08caae4280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'metrics' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Run SI on Split CIFAR-10\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43msi_split_cifar10\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepochs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m  \n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mType of res:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mtype\u001b[39m(res))\n\u001b[1;32m      5\u001b[0m accuracy_matrix \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/workspace/continual-learning-baselines/experiments/si_split_cifar10.py:36\u001b[0m, in \u001b[0;36msi_split_cifar10\u001b[0;34m(override_args)\u001b[0m\n\u001b[1;32m     32\u001b[0m criterion \u001b[38;5;241m=\u001b[39m CrossEntropyLoss()\n\u001b[1;32m     34\u001b[0m interactive_logger \u001b[38;5;241m=\u001b[39m avl\u001b[38;5;241m.\u001b[39mlogging\u001b[38;5;241m.\u001b[39mInteractiveLogger()\n\u001b[1;32m     35\u001b[0m evaluation_plugin \u001b[38;5;241m=\u001b[39m avl\u001b[38;5;241m.\u001b[39mtraining\u001b[38;5;241m.\u001b[39mplugins\u001b[38;5;241m.\u001b[39mEvaluationPlugin(\n\u001b[0;32m---> 36\u001b[0m     \u001b[43mmetrics\u001b[49m\u001b[38;5;241m.\u001b[39maccuracy_metrics(epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, experience\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m     37\u001b[0m     loggers\u001b[38;5;241m=\u001b[39m[interactive_logger]\n\u001b[1;32m     38\u001b[0m )\n\u001b[1;32m     40\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m SGD(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mlearning_rate, momentum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5e-4\u001b[39m)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Make SI task-aware: train only backbone + current task head\u001b[39;00m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'metrics' referenced before assignment"
     ]
    }
   ],
   "source": [
    "# Run SI on Split CIFAR-10\n",
    "res = si_split_cifar10({'epochs': 2})  \n",
    "print(\"Type of res:\", type(res))\n",
    "\n",
    "accuracy_matrix = []\n",
    "\n",
    "if isinstance(res, dict):\n",
    "    for key in res:\n",
    "        if 'Top1_Acc' in key:\n",
    "            accuracy_matrix.append(res[key])\n",
    "\n",
    "elif isinstance(res, list):\n",
    "    if len(res) > 0 and isinstance(res[0], dict):\n",
    "        # list of dicts\n",
    "        for r in res:\n",
    "            for key in r:\n",
    "                if 'Top1_Acc' in key:\n",
    "                    accuracy_matrix.append(r[key])\n",
    "    else:\n",
    "        # assume it's a list of accuracies already\n",
    "        accuracy_matrix = res\n",
    "\n",
    "accuracy_matrix = np.array(accuracy_matrix)\n",
    "print(\"Accuracy matrix shape:\", accuracy_matrix.shape)\n",
    "print(\"Accuracy matrix:\\n\", accuracy_matrix)\n",
    "\n",
    "# Compute CL metrics\n",
    "ACC = accuracy_matrix[-1]\n",
    "F = np.mean(np.max(accuracy_matrix[:-1]) - accuracy_matrix[-1])\n",
    "FWT = np.mean(accuracy_matrix[:-1])\n",
    "BWT = np.mean(accuracy_matrix[-1] - accuracy_matrix[:-1])\n",
    "PSM = ACC / (ACC + abs(F))\n",
    "\n",
    "print(\"ACC:\", ACC)\n",
    "print(\"F:\", F)\n",
    "print(\"FWT (approx.):\", FWT)\n",
    "print(\"BWT:\", BWT)\n",
    "print(\"PSM:\", PSM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4884d8cc-b460-46e1-8670-a3c043a31902",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
