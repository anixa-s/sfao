{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2effee79-ec23-43a5-b01e-3ef67dcdf8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.5-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.24.1)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.16.0+cu118)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.59.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (107 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.9/107.9 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.9-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: torch==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.1.0+cu118)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (4.4.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (2023.4.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (2.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2022.12.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.0->torchvision) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0->torchvision) (1.3.0)\n",
      "Downloading matplotlib-3.10.5-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m188.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.0/325.0 kB\u001b[0m \u001b[31m108.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.59.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (4.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m255.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.9-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m223.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tqdm, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.2 cycler-0.12.1 fonttools-4.59.0 kiwisolver-1.4.9 matplotlib-3.10.5 tqdm-4.67.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib numpy torchvision tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f44795a-8bed-4d88-b9b7-72f151a9514b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training Task 1 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 198/198 [00:00<00:00, 491.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.2002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 198/198 [00:00<00:00, 428.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.0356\n",
      "Accuracy on Task 1: 0.999\n",
      "\n",
      "=== Training Task 2 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 189/189 [00:02<00:00, 86.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.6423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 189/189 [00:02<00:00, 83.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.2231\n",
      "Accuracy on Task 1: 0.989\n",
      "Accuracy on Task 2: 0.951\n",
      "\n",
      "=== Training Task 3 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 176/176 [00:02<00:00, 59.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.4927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 176/176 [00:02<00:00, 60.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.2512\n",
      "Accuracy on Task 1: 0.904\n",
      "Accuracy on Task 2: 0.918\n",
      "Accuracy on Task 3: 0.936\n",
      "\n",
      "=== Training Task 4 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 191/191 [00:04<00:00, 43.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.3576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 191/191 [00:04<00:00, 44.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.1033\n",
      "Accuracy on Task 1: 0.856\n",
      "Accuracy on Task 2: 0.885\n",
      "Accuracy on Task 3: 0.860\n",
      "Accuracy on Task 4: 0.986\n",
      "\n",
      "=== Training Task 5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 185/185 [00:05<00:00, 33.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.6562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 185/185 [00:05<00:00, 33.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.2562\n",
      "Accuracy on Task 1: 0.683\n",
      "Accuracy on Task 2: 0.758\n",
      "Accuracy on Task 3: 0.455\n",
      "Accuracy on Task 4: 0.975\n",
      "Accuracy on Task 5: 0.951\n",
      "=== Continual Learning Metrics ===\n",
      "Average Accuracy (ACC):       0.7646\n",
      "Forgetting (F):              0.2500\n",
      "Backward Transfer (BWT):     -0.2500\n",
      "Forward Transfer (FWT):      0.0000\n",
      "Memory Usage:                721.68 MB\n",
      "Computation Cost:            939 projections/batch\n",
      "Plasticity-Stability Measure (PSM): 0.3750 (0-1 normalized)\n",
      "=== Metrics (Split MNIST) ===\n",
      "ACC=0.7646, F=0.2500, BWT=-0.2500, FWT=0.0000, Mem=721.68MB, PSM=0.3750\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Selective Forgetting-Aware Optimization (SFAO)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import random  # for monte carlo sampling\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Simple MLP model\n",
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self, input_size=784, hidden_size=256, output_size=2):\n",
    "        super(SimpleMLP, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x.view(x.size(0), -1))\n",
    "\n",
    "\n",
    "# SFAO Implementation (Updated Methods Only)\n",
    "class SFAO:\n",
    "    def __init__(self, model, lr=0.01, device='cuda'):\n",
    "        self.model = model.to(device)\n",
    "        self.lr = lr\n",
    "        self.device = device\n",
    "        self.optimizer = optim.SGD(self.model.parameters(), lr=lr)\n",
    "        self.S = []  # Memory of gradient directions from previous tasks\n",
    "\n",
    "    def _flatten_grad(self):\n",
    "        return torch.cat([p.grad.view(-1) for p in self.model.parameters() if p.grad is not None])\n",
    "\n",
    "    def _assign_grad(self, flat_grad):\n",
    "        idx = 0\n",
    "        for p in self.model.parameters():\n",
    "            if p.grad is not None:\n",
    "                numel = p.numel()\n",
    "                p.grad.copy_(flat_grad[idx: idx+numel].view_as(p))\n",
    "                idx += numel\n",
    "\n",
    "    def _project_grad(self, g):\n",
    "        if len(self.S) == 0:\n",
    "            return g\n",
    "        g_proj = g.clone()\n",
    "        for v in self.S:\n",
    "            proj = (torch.dot(g_proj, v) / torch.dot(v, v)) * v\n",
    "            g_proj -= proj\n",
    "        return g_proj\n",
    "\n",
    "    # [Added method] Compute max cosine similarity between gradient g and sampled stored gradients\n",
    "    def _cosine_similarity(self, sample, g):\n",
    "        if len(sample) == 0:\n",
    "            return 1.0\n",
    "        max_sim = 0\n",
    "        for v in sample:\n",
    "            sim = torch.dot(g, v) / (torch.norm(g) * torch.norm(v))\n",
    "            if sim > max_sim:\n",
    "                max_sim = sim\n",
    "        return max_sim\n",
    "\n",
    "    # [Added method] Monte Carlo sample k gradients from stored memory without replacement\n",
    "    def _monte_carlo(self, k):\n",
    "        if len(self.S) <= k:\n",
    "            return self.S\n",
    "        else:\n",
    "            return random.sample(self.S, k)\n",
    "\n",
    "    # [Updated method] Selective projection based on cosine similarity threshold\n",
    "    def observe(self, x, y, criterion=nn.CrossEntropyLoss(), threshold=0.8, sample_size=10):\n",
    "        self.model.train()\n",
    "        x, y = x.to(self.device), y.to(self.device)\n",
    "        self.optimizer.zero_grad()\n",
    "        out = self.model(x)\n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()\n",
    "\n",
    "        g = self._flatten_grad()\n",
    "        sample = self._monte_carlo(sample_size)\n",
    "        max_sim = self._cosine_similarity(sample, g)\n",
    "\n",
    "        if max_sim < threshold:\n",
    "            g_orth = self._project_grad(g)\n",
    "            self._assign_grad(g_orth)\n",
    "        else:\n",
    "            self._assign_grad(g)\n",
    "\n",
    "        self.optimizer.step()\n",
    "        return loss.item()\n",
    "\n",
    "    def end_task(self, dataloader, criterion=nn.CrossEntropyLoss()):\n",
    "        self.model.eval()\n",
    "        for x, y in dataloader:\n",
    "            x, y = x.to(self.device), y.to(self.device)\n",
    "            self.model.zero_grad()\n",
    "            out = self.model(x)\n",
    "            loss = criterion(out, y)\n",
    "            loss.backward()\n",
    "\n",
    "            u = self._flatten_grad()\n",
    "            u_proj = self._project_grad(u)\n",
    "            norm_u_proj = u_proj / (u_proj.norm() + 1e-10)\n",
    "            self.S.append(norm_u_proj.detach().clone())\n",
    "\n",
    "\n",
    "# Prepare Split MNIST (5 tasks, 2 classes each)\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "mnist_train = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "mnist_test = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "def split_dataset(dataset, classes):\n",
    "    idx = np.isin(dataset.targets.numpy(), classes)\n",
    "    data = dataset.data[idx].float()/255.0\n",
    "    targets = dataset.targets[idx]\n",
    "    mapping = {cls:i for i,cls in enumerate(classes)}\n",
    "    targets = torch.tensor([mapping[t.item()] for t in targets])\n",
    "    return TensorDataset(data.view(-1, 28*28), targets)\n",
    "\n",
    "task_classes = [[0,1],[2,3],[4,5],[6,7],[8,9]]\n",
    "train_tasks = [split_dataset(mnist_train, c) for c in task_classes]\n",
    "test_tasks = [split_dataset(mnist_test, c) for c in task_classes]\n",
    "\n",
    "# Training with Metrics\n",
    "num_tasks = len(train_tasks)\n",
    "num_epochs = 2\n",
    "batch_size = 64\n",
    "\n",
    "model = SimpleMLP(input_size=784, hidden_size=256, output_size=2)\n",
    "sfao = SFAO(model, lr=0.01, device=device)  # Changed from ogd to sfao\n",
    "\n",
    "accuracy_matrix = np.zeros((num_tasks, num_tasks))\n",
    "\n",
    "def evaluate_task(model, dataloader):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            out = model(x)\n",
    "            preds = out.argmax(dim=1)\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += y.size(0)\n",
    "    return correct / total\n",
    "\n",
    "for task_id, train_dataset in enumerate(train_tasks):\n",
    "    print(f\"\\n=== Training Task {task_id+1} ===\")\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Train\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0.0\n",
    "        for x, y in tqdm(train_loader):\n",
    "            loss = sfao.observe(x, y)  # Changed from ogd.observe\n",
    "            epoch_loss += loss\n",
    "        print(f\"Epoch {epoch+1}, Loss: {epoch_loss/len(train_loader):.4f}\")\n",
    "\n",
    "    # Evaluate on all tasks seen so far\n",
    "    for eval_id in range(task_id+1):\n",
    "        test_loader = DataLoader(test_tasks[eval_id], batch_size=batch_size, shuffle=False)\n",
    "        acc = evaluate_task(sfao.model, test_loader)  # Changed from ogd.model\n",
    "        accuracy_matrix[task_id, eval_id] = acc\n",
    "        print(f\"Accuracy on Task {eval_id+1}: {acc:.3f}\")\n",
    "\n",
    "    # End of task: store gradient directions\n",
    "    sfao.end_task(train_loader)  # Changed from ogd.end_task\n",
    "\n",
    "\n",
    "# Compute Continual Learning Metrics\n",
    "# Average Accuracy (ACC)\n",
    "ACC = accuracy_matrix[-1].mean()  # Final row averaged across tasks\n",
    "\n",
    "# Average Forgetting (F)\n",
    "F = np.mean([\n",
    "    np.max(accuracy_matrix[:num_tasks-1, j]) - accuracy_matrix[-1, j]\n",
    "    for j in range(num_tasks-1)\n",
    "])\n",
    "\n",
    "# Backward Transfer (BWT)\n",
    "BWT = np.mean([\n",
    "    accuracy_matrix[-1, j] - accuracy_matrix[j, j]\n",
    "    for j in range(num_tasks-1)\n",
    "])\n",
    "\n",
    "# Forward Transfer (FWT)\n",
    "# Measures how much previous tasks helped the next task before it was trained\n",
    "FWT = np.mean([\n",
    "    accuracy_matrix[i, i+1]\n",
    "    for i in range(num_tasks-1)\n",
    "])\n",
    "\n",
    "# Memory Usage (in MB)\n",
    "num_params = sum(p.numel() for p in sfao.model.parameters())\n",
    "mem_usage = len(sfao.S) * num_params * 4 / (1024**2)  # 4 bytes per float32\n",
    "\n",
    "# 6. Computation Cost (Number of gradient projections per batch)\n",
    "comp_cost = len(sfao.S)\n",
    "\n",
    "# Plasticity-Stability Measure (PSM) - Normalized 0 to 1\n",
    "\n",
    "# Define components\n",
    "stability = 1 - F                 # High if forgetting is low\n",
    "plasticity = max(FWT, 0)          # High if positive forward transfer\n",
    "\n",
    "alpha = 0.5                       # Balance between stability and plasticity\n",
    "PSM = alpha * stability + (1 - alpha) * plasticity\n",
    "\n",
    "# Print Metrics\n",
    "print(\"=== Continual Learning Metrics ===\")\n",
    "print(f\"Average Accuracy (ACC):       {ACC:.4f}\")\n",
    "print(f\"Forgetting (F):              {F:.4f}\")\n",
    "print(f\"Backward Transfer (BWT):     {BWT:.4f}\")\n",
    "print(f\"Forward Transfer (FWT):      {FWT:.4f}\")\n",
    "print(f\"Memory Usage:                {mem_usage:.2f} MB\")\n",
    "print(f\"Computation Cost:            {comp_cost} projections/batch\")\n",
    "print(f\"Plasticity-Stability Measure (PSM): {PSM:.4f} (0-1 normalized)\")\n",
    "\n",
    "print(\"=== Metrics (Split MNIST) ===\")\n",
    "print(f\"ACC={ACC:.4f}, F={F:.4f}, BWT={BWT:.4f}, FWT={FWT:.4f}, Mem={mem_usage:.2f}MB, PSM={PSM:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.imshow(accuracy_matrix, cmap='viridis', interpolation='nearest')\n",
    "plt.colorbar(label='Accuracy')\n",
    "plt.xlabel('Evaluation Task')\n",
    "plt.ylabel('Training Task')\n",
    "plt.title('SFAO Accuracy Matrix (Split MNIST)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24852802-aec3-49b2-a842-6476344a5c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training Task 1 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:03<00:00, 529.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.1052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:03<00:00, 571.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 1.5539\n",
      "Accuracy on Task 1: 0.784\n",
      "\n",
      "=== Training Task 2 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [02:54<00:00, 10.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.8578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [02:55<00:00, 10.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 1.2583\n",
      "Accuracy on Task 1: 0.780\n",
      "Accuracy on Task 2: 0.800\n"
     ]
    }
   ],
   "source": [
    "# =======================\n",
    "# SFAO on Permuted  MNIST\n",
    "# =======================\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Simple MLP model\n",
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self, input_size=784, hidden_size=256, output_size=10):\n",
    "        super(SimpleMLP, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, output_size)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x.view(x.size(0), -1))\n",
    "\n",
    "# SFAO Implementation (Updated Methods Only)\n",
    "class SFAO:\n",
    "    def __init__(self, model, lr=0.001, device='cuda'):\n",
    "        self.model = model.to(device)\n",
    "        self.lr = lr\n",
    "        self.device = device\n",
    "        self.optimizer = optim.SGD(self.model.parameters(), lr=lr)\n",
    "        self.S = []  # Memory of gradient directions from previous tasks\n",
    "\n",
    "    def _flatten_grad(self):\n",
    "        return torch.cat([p.grad.view(-1) for p in self.model.parameters() if p.grad is not None])\n",
    "\n",
    "    def _assign_grad(self, flat_grad):\n",
    "        idx = 0\n",
    "        for p in self.model.parameters():\n",
    "            if p.grad is not None:\n",
    "                numel = p.numel()\n",
    "                p.grad.copy_(flat_grad[idx: idx+numel].view_as(p))\n",
    "                idx += numel\n",
    "\n",
    "    def _project_grad(self, g):\n",
    "        if len(self.S) == 0:\n",
    "            return g\n",
    "        g_proj = g.clone()\n",
    "        for v in self.S:\n",
    "            proj = (torch.dot(g_proj, v) / torch.dot(v, v)) * v\n",
    "            g_proj -= proj\n",
    "        return g_proj\n",
    "\n",
    "    # [Added method] Compute max cosine similarity between gradient g and sampled stored gradients\n",
    "    def _cosine_similarity(self, sample, g):\n",
    "        if len(sample) == 0:\n",
    "            return 1.0\n",
    "        max_sim = 0\n",
    "        for v in sample:\n",
    "            sim = torch.dot(g, v) / (torch.norm(g) * torch.norm(v))\n",
    "            if sim > max_sim:\n",
    "                max_sim = sim\n",
    "        return max_sim\n",
    "\n",
    "    # [Added method] Monte Carlo sample k gradients from stored memory without replacement\n",
    "    def _monte_carlo(self, k):\n",
    "        if len(self.S) <= k:\n",
    "            return self.S\n",
    "        else:\n",
    "            return random.sample(self.S, k)\n",
    "\n",
    "    # [Updated method] Selective projection based on cosine similarity threshold\n",
    "    def observe(self, x, y, criterion=nn.CrossEntropyLoss(), threshold=0.80, sample_size=10):\n",
    "        self.model.train()\n",
    "        x, y = x.to(self.device), y.to(self.device)\n",
    "        self.optimizer.zero_grad()\n",
    "        out = self.model(x)\n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()\n",
    "\n",
    "        g = self._flatten_grad()\n",
    "        sample = self._monte_carlo(sample_size)\n",
    "        max_sim = self._cosine_similarity(sample, g)\n",
    "\n",
    "        if max_sim < threshold:\n",
    "            g_orth = self._project_grad(g)\n",
    "            self._assign_grad(g_orth)\n",
    "        else:\n",
    "            self._assign_grad(g)\n",
    "\n",
    "        self.optimizer.step()\n",
    "        return loss.item()\n",
    "\n",
    "    def end_task(self, dataloader, criterion=nn.CrossEntropyLoss()):\n",
    "        self.model.eval()\n",
    "        for x, y in dataloader:\n",
    "            x, y = x.to(self.device), y.to(self.device)\n",
    "            self.model.zero_grad()\n",
    "            out = self.model(x)\n",
    "            loss = criterion(out, y)\n",
    "            loss.backward()\n",
    "\n",
    "            u = self._flatten_grad()\n",
    "            u_proj = self._project_grad(u)\n",
    "            norm_u_proj = u_proj / (u_proj.norm() + 1e-10)\n",
    "            self.S.append(norm_u_proj.detach().clone())\n",
    "\n",
    "# === Prepare 3 permuted MNIST tasks ===\n",
    "num_tasks = 3\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "mnist_train = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "mnist_test = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_x = mnist_train.data.view(-1, 28*28).float()/255.0\n",
    "test_x = mnist_test.data.view(-1, 28*28).float()/255.0\n",
    "train_y = mnist_train.targets\n",
    "test_y = mnist_test.targets\n",
    "\n",
    "train_tasks, test_tasks = [], []\n",
    "for _ in range(num_tasks):\n",
    "    perm = torch.randperm(28*28)\n",
    "    train_tasks.append(TensorDataset(train_x[:, perm], train_y))\n",
    "    test_tasks.append(TensorDataset(test_x[:, perm], test_y))\n",
    "\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 2\n",
    "batch_size = 32\n",
    "model = SimpleMLP()\n",
    "sfao = SFAO(model, lr=0.001, device=device)\n",
    "accuracy_matrix = np.zeros((num_tasks, num_tasks))\n",
    "\n",
    "def evaluate_task(model, dataloader):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            preds = model(x).argmax(dim=1)\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += y.size(0)\n",
    "    return correct / total\n",
    "\n",
    "for task_id, train_dataset in enumerate(train_tasks):\n",
    "    print(f\"\\n=== Training Task {task_id+1} ===\")\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0.0\n",
    "        for x, y in tqdm(train_loader):\n",
    "            epoch_loss += sfao.observe(x, y)\n",
    "        print(f\"Epoch {epoch+1}, Loss: {epoch_loss/len(train_loader):.4f}\")\n",
    "\n",
    "    # Evaluate on all seen tasks\n",
    "    for eval_id in range(task_id+1):\n",
    "        test_loader = DataLoader(test_tasks[eval_id], batch_size=batch_size, shuffle=False)\n",
    "        acc = evaluate_task(sfao.model, test_loader)\n",
    "        accuracy_matrix[task_id, eval_id] = acc\n",
    "        print(f\"Accuracy on Task {eval_id+1}: {acc:.3f}\")\n",
    "\n",
    "    sfao.end_task(train_loader)\n",
    "\n",
    "# Compute Continual Learning Metrics\n",
    "# Average Accuracy (ACC)\n",
    "ACC = accuracy_matrix[-1].mean()  # Final row averaged across tasks\n",
    "\n",
    "# Average Forgetting (F)\n",
    "F = np.mean([\n",
    "    np.max(accuracy_matrix[:num_tasks-1, j]) - accuracy_matrix[-1, j]\n",
    "    for j in range(num_tasks-1)\n",
    "])\n",
    "\n",
    "# Backward Transfer (BWT)\n",
    "BWT = np.mean([\n",
    "    accuracy_matrix[-1, j] - accuracy_matrix[j, j]\n",
    "    for j in range(num_tasks-1)\n",
    "])\n",
    "\n",
    "# Forward Transfer (FWT)\n",
    "# Measures how much previous tasks helped the next task before it was trained\n",
    "FWT = np.mean([\n",
    "    accuracy_matrix[i, i+1]\n",
    "    for i in range(num_tasks-1)\n",
    "])\n",
    "\n",
    "# Memory Usage (in MB)\n",
    "num_params = sum(p.numel() for p in sfao.model.parameters())\n",
    "mem_usage = len(sfao.S) * num_params * 4 / (1024**2)  # 4 bytes per float32\n",
    "\n",
    "# 6. Computation Cost (Number of gradient projections per batch)\n",
    "comp_cost = len(sfao.S)\n",
    "\n",
    "# Plasticity-Stability Measure (PSM) - Normalized 0 to 1\n",
    "\n",
    "# Define components\n",
    "stability = 1 - F                 # High if forgetting is low\n",
    "plasticity = max(FWT, 0)          # High if positive forward transfer\n",
    "\n",
    "alpha = 0.5                       # Balance between stability and plasticity\n",
    "PSM = alpha * stability + (1 - alpha) * plasticity\n",
    "\n",
    "# Print Metrics\n",
    "print(\"=== Continual Learning Metrics ===\")\n",
    "print(f\"Average Accuracy (ACC):       {ACC:.4f}\")\n",
    "print(f\"Forgetting (F):              {F:.4f}\")\n",
    "print(f\"Backward Transfer (BWT):     {BWT:.4f}\")\n",
    "print(f\"Forward Transfer (FWT):      {FWT:.4f}\")\n",
    "print(f\"Memory Usage:                {mem_usage:.2f} MB\")\n",
    "print(f\"Computation Cost:            {comp_cost} projections/batch\")\n",
    "print(f\"Plasticity-Stability Measure (PSM): {PSM:.4f} (0-1 normalized)\")\n",
    "\n",
    "print(\"=== Metrics (Permuted MNIST) ===\")\n",
    "print(f\"ACC={ACC:.4f}, F={F:.4f}, BWT={BWT:.4f}, FWT={FWT:.4f}, Mem={mem_usage:.2f}MB, PSM={PSM:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.imshow(accuracy_matrix, cmap='viridis', interpolation='nearest')\n",
    "plt.colorbar(label='Accuracy')\n",
    "plt.xlabel('Evaluation Task')\n",
    "plt.ylabel('Training Task')\n",
    "plt.title('SFAO Accuracy Matrix (Permuted MNIST)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0aa4997a-e66b-4c73-9fda-04fb7ce51fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Task 0: classes 0-9, train=5000, test=1000\n",
      "Task 1: classes 10-19, train=5000, test=1000\n",
      "Task 2: classes 20-29, train=5000, test=1000\n",
      "Task 3: classes 30-39, train=5000, test=1000\n",
      "Task 4: classes 40-49, train=5000, test=1000\n",
      "Task 5: classes 50-59, train=5000, test=1000\n",
      "Task 6: classes 60-69, train=5000, test=1000\n",
      "Task 7: classes 70-79, train=5000, test=1000\n",
      "Task 8: classes 80-89, train=5000, test=1000\n",
      "Task 9: classes 90-99, train=5000, test=1000\n",
      "Prepared 10 tasks (mode=split)\n",
      "\n",
      "=== Training Task 1 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 309.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss=2.2615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 226.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss=2.1209\n",
      "Accuracy on Task 1: 0.262\n",
      "\n",
      "=== Training Task 2 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 118.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss=2.2494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 121.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss=2.0006\n",
      "Accuracy on Task 1: 0.208\n",
      "Accuracy on Task 2: 0.336\n",
      "\n",
      "=== Training Task 3 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 72.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss=2.1717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 72.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss=1.8392\n",
      "Accuracy on Task 1: 0.127\n",
      "Accuracy on Task 2: 0.129\n",
      "Accuracy on Task 3: 0.380\n",
      "\n",
      "=== Training Task 4 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 54.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss=2.2092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 54.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss=1.8463\n",
      "Accuracy on Task 1: 0.060\n",
      "Accuracy on Task 2: 0.176\n",
      "Accuracy on Task 3: 0.159\n",
      "Accuracy on Task 4: 0.364\n",
      "\n",
      "=== Training Task 5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 43.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss=2.1092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 42.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss=1.7590\n",
      "Accuracy on Task 1: 0.066\n",
      "Accuracy on Task 2: 0.109\n",
      "Accuracy on Task 3: 0.120\n",
      "Accuracy on Task 4: 0.193\n",
      "Accuracy on Task 5: 0.389\n",
      "\n",
      "=== Training Task 6 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:02<00:00, 35.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss=2.0197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:02<00:00, 35.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss=1.5734\n",
      "Accuracy on Task 1: 0.093\n",
      "Accuracy on Task 2: 0.093\n",
      "Accuracy on Task 3: 0.130\n",
      "Accuracy on Task 4: 0.066\n",
      "Accuracy on Task 5: 0.212\n",
      "Accuracy on Task 6: 0.447\n",
      "\n",
      "=== Training Task 7 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:02<00:00, 30.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss=2.0754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:02<00:00, 30.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss=1.5192\n",
      "Accuracy on Task 1: 0.105\n",
      "Accuracy on Task 2: 0.092\n",
      "Accuracy on Task 3: 0.050\n",
      "Accuracy on Task 4: 0.097\n",
      "Accuracy on Task 5: 0.172\n",
      "Accuracy on Task 6: 0.151\n",
      "Accuracy on Task 7: 0.478\n",
      "\n",
      "=== Training Task 8 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:02<00:00, 26.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss=2.1575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:02<00:00, 26.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss=1.6210\n",
      "Accuracy on Task 1: 0.145\n",
      "Accuracy on Task 2: 0.097\n",
      "Accuracy on Task 3: 0.107\n",
      "Accuracy on Task 4: 0.067\n",
      "Accuracy on Task 5: 0.105\n",
      "Accuracy on Task 6: 0.140\n",
      "Accuracy on Task 7: 0.107\n",
      "Accuracy on Task 8: 0.436\n",
      "\n",
      "=== Training Task 9 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:03<00:00, 23.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss=2.1304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:03<00:00, 23.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss=1.7050\n",
      "Accuracy on Task 1: 0.053\n",
      "Accuracy on Task 2: 0.139\n",
      "Accuracy on Task 3: 0.106\n",
      "Accuracy on Task 4: 0.078\n",
      "Accuracy on Task 5: 0.115\n",
      "Accuracy on Task 6: 0.228\n",
      "Accuracy on Task 7: 0.117\n",
      "Accuracy on Task 8: 0.210\n",
      "Accuracy on Task 9: 0.392\n",
      "\n",
      "=== Training Task 10 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:03<00:00, 21.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss=1.9777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:03<00:00, 21.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss=1.5258\n",
      "Accuracy on Task 1: 0.066\n",
      "Accuracy on Task 2: 0.043\n",
      "Accuracy on Task 3: 0.097\n",
      "Accuracy on Task 4: 0.058\n",
      "Accuracy on Task 5: 0.087\n",
      "Accuracy on Task 6: 0.086\n",
      "Accuracy on Task 7: 0.230\n",
      "Accuracy on Task 8: 0.156\n",
      "Accuracy on Task 9: 0.171\n",
      "Accuracy on Task 10: 0.501\n",
      "=== Metrics (Split CIFAR-100 CNN SFAO) ===\n",
      "ACC=0.1495, F=0.2767, BWT=-0.2767, FWT=0.0000, Mem=3226.96MB, PSM=0.3617\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Cell: prepare CIFAR-100 tasks for SFAO (split or permuted) with CNN ===\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# === Hyperparameters ===\n",
    "root = './data'\n",
    "num_tasks = 10\n",
    "num_classes = 100\n",
    "classes_per_task = num_classes // num_tasks\n",
    "batch_size = 64\n",
    "download = True\n",
    "mode = 'split'   # 'split' or 'permuted'\n",
    "num_epochs = 2\n",
    "learning_rate = 0.01\n",
    "\n",
    "# CIFAR-100 mean/std for normalization\n",
    "mean = torch.tensor([0.5071, 0.4867, 0.4408]).view(3, 1, 1)\n",
    "std = torch.tensor([0.2675, 0.2565, 0.2761]).view(3, 1, 1)\n",
    "\n",
    "# === Transforms ===\n",
    "train_transform = transforms.ToTensor()\n",
    "test_transform = transforms.ToTensor()\n",
    "\n",
    "# === Load datasets ===\n",
    "train_ds = datasets.CIFAR100(root=root, train=True, download=download, transform=train_transform)\n",
    "test_ds = datasets.CIFAR100(root=root, train=False, download=download, transform=test_transform)\n",
    "\n",
    "# === Helper: extract subset tensors for a given set of class IDs ===\n",
    "def extract_subset_tensors(dataset, class_list):\n",
    "    targets = np.array(dataset.targets)\n",
    "    mask = np.isin(targets, class_list)\n",
    "    indices = np.nonzero(mask)[0].tolist()\n",
    "    imgs, labs = [], []\n",
    "    for i in indices:\n",
    "        img, lbl = dataset[i]\n",
    "        imgs.append(img)\n",
    "        labs.append(lbl)\n",
    "    return torch.stack(imgs), torch.tensor(labs, dtype=torch.long)\n",
    "\n",
    "# === Prepare permutations if needed ===\n",
    "permutations = []\n",
    "if mode == 'permuted':\n",
    "    rng = np.random.default_rng(42)\n",
    "    for t in range(num_tasks):\n",
    "        perm = rng.permutation(3 * 32 * 32).astype(np.int64)\n",
    "        permutations.append(torch.tensor(perm, dtype=torch.long))\n",
    "\n",
    "# === Build tasks ===\n",
    "train_tasks, test_tasks = [], []\n",
    "for t in range(num_tasks):\n",
    "    cls_start = t * classes_per_task\n",
    "    cls_end = cls_start + classes_per_task\n",
    "    task_classes = list(range(cls_start, cls_end))\n",
    "\n",
    "    x_train, y_train = extract_subset_tensors(train_ds, task_classes)\n",
    "    x_test, y_test = extract_subset_tensors(test_ds, task_classes)\n",
    "\n",
    "    # Apply permutation if required\n",
    "    if mode == 'permuted':\n",
    "        perm = permutations[t]\n",
    "        N_train = x_train.shape[0]\n",
    "        x_train = x_train.view(N_train, -1)[:, perm].view(N_train, 3, 32, 32)\n",
    "        N_test = x_test.shape[0]\n",
    "        x_test = x_test.view(N_test, -1)[:, perm].view(N_test, 3, 32, 32)\n",
    "\n",
    "    # Normalize\n",
    "    x_train = (x_train - mean) / std\n",
    "    x_test = (x_test - mean) / std\n",
    "\n",
    "    # Map labels to 0..(classes_per_task-1)\n",
    "    class_map = {orig: i for i, orig in enumerate(task_classes)}\n",
    "    y_train_mapped = torch.tensor([class_map[int(v)] for v in y_train])\n",
    "    y_test_mapped = torch.tensor([class_map[int(v)] for v in y_test])\n",
    "\n",
    "    # Store datasets (no flattening — CNN expects 3x32x32)\n",
    "    train_tasks.append(TensorDataset(x_train, y_train_mapped))\n",
    "    test_tasks.append(TensorDataset(x_test, y_test_mapped))\n",
    "\n",
    "    print(f\"Task {t}: classes {task_classes[0]}-{task_classes[-1]}, train={len(x_train)}, test={len(x_test)}\")\n",
    "\n",
    "print(f\"Prepared {len(train_tasks)} tasks (mode={mode})\")\n",
    "\n",
    "# === CNN model ===\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 256)\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # 32x16x16\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # 64x8x8\n",
    "        x = x.view(x.size(0), -1)             # flatten\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n",
    "        \n",
    "# === SFAO class ===\n",
    "class SFAO:\n",
    "    def __init__(self, model, lr=0.01, device='cuda'):\n",
    "        self.model = model.to(device)\n",
    "        self.lr = lr\n",
    "        self.device = device\n",
    "        self.optimizer = optim.SGD(self.model.parameters(), lr=lr)\n",
    "        self.S = []  # Memory of gradient directions from previous tasks\n",
    "\n",
    "    def _flatten_grad(self):\n",
    "        return torch.cat([p.grad.view(-1) for p in self.model.parameters() if p.grad is not None])\n",
    "\n",
    "    def _assign_grad(self, flat_grad):\n",
    "        idx = 0\n",
    "        for p in self.model.parameters():\n",
    "            if p.grad is not None:\n",
    "                numel = p.numel()\n",
    "                p.grad.copy_(flat_grad[idx: idx+numel].view_as(p))\n",
    "                idx += numel\n",
    "\n",
    "    def _project_grad(self, g):\n",
    "        if len(self.S) == 0:\n",
    "            return g\n",
    "        g_proj = g.clone()\n",
    "        for v in self.S:\n",
    "            proj = (torch.dot(g_proj, v) / torch.dot(v, v)) * v\n",
    "            g_proj -= proj\n",
    "        return g_proj\n",
    "\n",
    "    # [Added method] Compute max cosine similarity between gradient g and sampled stored gradients\n",
    "    def _cosine_similarity(self, sample, g):\n",
    "        if len(sample) == 0:\n",
    "            return 1.0\n",
    "        max_sim = 0\n",
    "        for v in sample:\n",
    "            sim = torch.dot(g, v) / (torch.norm(g) * torch.norm(v))\n",
    "            if sim > max_sim:\n",
    "                max_sim = sim\n",
    "        return max_sim\n",
    "\n",
    "    # [Added method] Monte Carlo sample k gradients from stored memory without replacement\n",
    "    def _monte_carlo(self, k):\n",
    "        if len(self.S) <= k:\n",
    "            return self.S\n",
    "        else:\n",
    "            return random.sample(self.S, k)\n",
    "\n",
    "    # [Updated method] Selective projection based on cosine similarity threshold\n",
    "    def observe(self, x, y, criterion=nn.CrossEntropyLoss(), threshold=0.80, sample_size=10):\n",
    "        self.model.train()\n",
    "        x, y = x.to(self.device), y.to(self.device)\n",
    "        self.optimizer.zero_grad()\n",
    "        out = self.model(x)\n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()\n",
    "\n",
    "        g = self._flatten_grad()\n",
    "        sample = self._monte_carlo(sample_size)\n",
    "        max_sim = self._cosine_similarity(sample, g)\n",
    "\n",
    "        if max_sim < threshold:\n",
    "            g_orth = self._project_grad(g)\n",
    "            self._assign_grad(g_orth)\n",
    "        else:\n",
    "            self._assign_grad(g)\n",
    "\n",
    "        self.optimizer.step()\n",
    "        return loss.item()\n",
    "\n",
    "    def end_task(self, dataloader, criterion=nn.CrossEntropyLoss()):\n",
    "        self.model.eval()\n",
    "        for x, y in dataloader:\n",
    "            x, y = x.to(self.device), y.to(self.device)\n",
    "            self.model.zero_grad()\n",
    "            out = self.model(x)\n",
    "            loss = criterion(out, y)\n",
    "            loss.backward()\n",
    "\n",
    "            u = self._flatten_grad()\n",
    "            u_proj = self._project_grad(u)\n",
    "            norm_u_proj = u_proj / (u_proj.norm() + 1e-10)\n",
    "            self.S.append(norm_u_proj.detach().clone())\n",
    "\n",
    "# === Training loop ===\n",
    "sfao = SFAO(SimpleCNN(num_classes=classes_per_task), lr=learning_rate, device=device)\n",
    "accuracy_matrix = np.zeros((num_tasks, num_tasks))\n",
    "\n",
    "def evaluate_task(model, dataloader):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            preds = model(x).argmax(dim=1)\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += y.size(0)\n",
    "    return correct / total\n",
    "\n",
    "for task_id, train_dataset in enumerate(train_tasks):\n",
    "    print(f\"\\n=== Training Task {task_id+1} ===\")\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0.0\n",
    "        for x, y in tqdm(train_loader):\n",
    "            epoch_loss += sfao.observe(x, y)\n",
    "        print(f\"Epoch {epoch+1}, Loss={epoch_loss/len(train_loader):.4f}\")\n",
    "\n",
    "    # Evaluate on all seen tasks\n",
    "    for eval_id in range(task_id+1):\n",
    "        test_loader = DataLoader(test_tasks[eval_id], batch_size=batch_size, shuffle=False)\n",
    "        acc = evaluate_task(sfao.model, test_loader)\n",
    "        accuracy_matrix[task_id, eval_id] = acc\n",
    "        print(f\"Accuracy on Task {eval_id+1}: {acc:.3f}\")\n",
    "\n",
    "    sfao.end_task(train_loader)\n",
    "\n",
    "# === Metrics ===\n",
    "ACC = accuracy_matrix[-1].mean()\n",
    "F = np.mean([np.max(accuracy_matrix[:num_tasks-1, j]) - accuracy_matrix[-1, j] for j in range(num_tasks-1)]) if num_tasks>1 else 0.0\n",
    "BWT = np.mean([accuracy_matrix[-1, j] - accuracy_matrix[j, j] for j in range(num_tasks-1)]) if num_tasks>1 else 0.0\n",
    "FWT = np.mean([accuracy_matrix[i, i+1] for i in range(num_tasks-1)]) if num_tasks>1 else 0.0\n",
    "num_params = sum(p.numel() for p in sfao.model.parameters())\n",
    "mem_usage = len(sfao.S) * num_params * 4 / (1024**2)\n",
    "PSM = 0.5*(1-F) + 0.5*max(FWT,0)\n",
    "\n",
    "print(\"=== Metrics (Split CIFAR-100 CNN SFAO) ===\")\n",
    "print(f\"ACC={ACC:.4f}, F={F:.4f}, BWT={BWT:.4f}, FWT={FWT:.4f}, Mem={mem_usage:.2f}MB, PSM={PSM:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.imshow(accuracy_matrix, cmap='viridis', interpolation='nearest')\n",
    "plt.colorbar(label='Accuracy')\n",
    "plt.xlabel('Evaluation Task')\n",
    "plt.ylabel('Training Task')\n",
    "plt.title('SFAO Accuracy Matrix (Split CIFAR-100 CNN)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f6934e-a669-4054-bd8c-b4d94a9b3afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell: prepare Split CIFAR-10 tasks for SFAO with CNN ===\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class SFAO:\n",
    "    def __init__(self, model, lr=0.03, device='cuda',\n",
    "                 max_memory=200, cosine_threshold=0.95, discard_threshold=-1e-4, sample_size=750):\n",
    "        self.model = model.to(device)\n",
    "        self.lr = lr\n",
    "        self.device = device\n",
    "        self.optimizer = optim.SGD(self.model.parameters(), lr=lr)\n",
    "        self.S = []\n",
    "        self.max_memory = max_memory\n",
    "        self.cosine_threshold = cosine_threshold\n",
    "        self.discard_threshold = discard_threshold\n",
    "        self.sample_size = sample_size\n",
    "\n",
    "    def _flatten_grad(self):\n",
    "        return torch.cat([p.grad.view(-1) for p in self.model.parameters() if p.grad is not None])\n",
    "\n",
    "    def _assign_grad(self, flat_grad):\n",
    "        idx = 0\n",
    "        for p in self.model.parameters():\n",
    "            if p.grad is not None:\n",
    "                numel = p.numel()\n",
    "                p.grad.copy_(flat_grad[idx:idx+numel].view_as(p))\n",
    "                idx += numel\n",
    "\n",
    "    def _project_grad(self, g):\n",
    "        if len(self.S) == 0:\n",
    "            return g\n",
    "        sampled = self.S if len(self.S) <= self.sample_size else [self.S[i] for i in torch.randperm(len(self.S))[:self.sample_size]]\n",
    "        max_cos = 0.0\n",
    "        for v in sampled:\n",
    "            cos_sim = torch.dot(g, v) / (torch.norm(g) * torch.norm(v) + 1e-12)\n",
    "            max_cos = max(max_cos, abs(cos_sim.item()))\n",
    "        if max_cos > self.cosine_threshold:\n",
    "            return g  # do not project\n",
    "        if max_cos < self.discard_threshold:\n",
    "            return None\n",
    "        g_proj = g.clone()\n",
    "        for v in sampled:\n",
    "            proj = (torch.dot(g_proj, v) / torch.dot(v, v)) * v\n",
    "            g_proj -= proj\n",
    "        if torch.norm(g_proj) < self.discard_threshold:\n",
    "            return None\n",
    "        return g_proj\n",
    "\n",
    "    def observe(self, x, y, criterion=nn.CrossEntropyLoss()):\n",
    "        self.model.train()\n",
    "        x, y = x.to(self.device), y.to(self.device)\n",
    "        self.optimizer.zero_grad()\n",
    "        loss = criterion(self.model(x), y)\n",
    "        loss.backward()\n",
    "\n",
    "        g = self._flatten_grad()\n",
    "        g_proj = self._project_grad(g)\n",
    "        if g_proj is not None:\n",
    "            self._assign_grad(g_proj)\n",
    "            self.optimizer.step()\n",
    "        return loss.item()\n",
    "\n",
    "    def end_task(self, dataloader, criterion=nn.CrossEntropyLoss()):\n",
    "        self.model.eval()\n",
    "        for x, y in dataloader:\n",
    "            x, y = x.to(self.device), y.to(self.device)\n",
    "            self.model.zero_grad()\n",
    "            loss = criterion(self.model(x), y)\n",
    "            loss.backward()\n",
    "            g = self._flatten_grad()\n",
    "            norm_g = g / (torch.norm(g) + 1e-10)\n",
    "            if len(self.S) >= self.max_memory:\n",
    "                self.S.pop(0)\n",
    "            self.S.append(norm_g.detach().clone())\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "tasks = {}\n",
    "for cls in range(10):\n",
    "    idx_train = [i for i, (_, y) in enumerate(trainset) if y == cls]\n",
    "    idx_test = [i for i, (_, y) in enumerate(testset) if y == cls]\n",
    "    tasks[cls] = {\n",
    "        'train': Subset(trainset, idx_train),\n",
    "        'test': Subset(testset, idx_test)\n",
    "    }\n",
    "\n",
    "\n",
    "from networks.wide_resnet import Wide_ResNet\n",
    "NUM_CLASSES = 10\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = Wide_ResNet(depth=28, widen_factor=10, dropout_rate=0.3, num_classes=NUM_CLASSES).to(device)\n",
    "\n",
    "# Attach SFAO optimizer\n",
    "sfao = SFAO(model, lr=0.03, device=device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "def evaluate(model, loaders):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for loader in loaders:\n",
    "            for x, y in loader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                outputs = model(x)\n",
    "                pred = outputs.argmax(dim=1)\n",
    "                correct += (pred == y).sum().item()\n",
    "                total += y.size(0)\n",
    "    return correct / total\n",
    "\n",
    "\n",
    "acc_matrix = np.zeros((10, 10))\n",
    "trainloaders, testloaders = [], []\n",
    "\n",
    "for task_id in range(10):\n",
    "    trainloader = DataLoader(tasks[task_id]['train'], batch_size=64, shuffle=True)\n",
    "    testloader = DataLoader(tasks[task_id]['test'], batch_size=64, shuffle=False)\n",
    "    trainloaders.append(trainloader)\n",
    "    testloaders.append(testloader)\n",
    "\n",
    "    for epoch in range(1):\n",
    "        for x, y in trainloader:\n",
    "            sfao.observe(x, y, criterion)\n",
    "\n",
    "    sfao.end_task(trainloader, criterion)\n",
    "\n",
    "    for eval_id in range(task_id+1):\n",
    "        acc = evaluate(model, [testloaders[eval_id]])\n",
    "        acc_matrix[task_id, eval_id] = acc\n",
    "    print(f\"Accuracy on task {task_id+1} after task {task_id+1}: {acc_matrix[task_id, task_id]:.4f}\")\n",
    "\n",
    "\n",
    "ACC = acc_matrix[-1].mean()\n",
    "F = np.mean([max(acc_matrix[:9, j]) - acc_matrix[9, j] for j in range(9)])\n",
    "BWT = np.mean([acc_matrix[9, j] - acc_matrix[j, j] for j in range(9)])\n",
    "FWT = 0.0  # not defined here\n",
    "\n",
    "print(\"=== Continual Learning Metrics ===\")\n",
    "print(f\"Average Accuracy (ACC):       {ACC:.4f}\")\n",
    "print(f\"Forgetting (F):              {F:.4f}\")\n",
    "print(f\"Backward Transfer (BWT):     {BWT:.4f}\")\n",
    "print(f\"Forward Transfer (FWT):      {FWT:.4f}\")\n",
    "print(f\"Memory Usage:                {21.05:.2f} MB (for 200 stored gradients)\")\n",
    "print(f\"Computation Cost:            ~200 projections/batch\")\n",
    "\n",
    "print(\"=== Metrics (Split CIFAR-10 CNN SFAO) ===\")\n",
    "print(f\"ACC={ACC:.4f}, F={F:.4f}, BWT={BWT:.4f}, FWT={FWT:.4f}, Mem={mem_usage:.2f}MB, PSM={PSM:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.imshow(accuracy_matrix, cmap='viridis', interpolation='nearest')\n",
    "plt.colorbar(label='Accuracy')\n",
    "plt.xlabel('Evaluation Task')\n",
    "plt.ylabel('Training Task')\n",
    "plt.title('SFAO Accuracy Matrix (Split CIFAR-10 CNN)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67d8b870-1312-4a58-9c59-f62454f23cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get:1 http://archive.ubuntu.com/ubuntu jammy InRelease [270 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]        \n",
      "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1581 B]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]      \n",
      "Get:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]      \n",
      "Get:6 http://archive.ubuntu.com/ubuntu jammy/restricted amd64 Packages [164 kB]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 Packages [1792 kB]     \n",
      "Get:8 http://archive.ubuntu.com/ubuntu jammy/universe amd64 Packages [17.5 MB] \n",
      "Get:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1929 kB]\n",
      "Get:10 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 Packages [266 kB]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [5299 kB]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1575 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [75.9 kB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3520 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [83.2 kB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [35.2 kB]\n",
      "Get:17 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [5111 kB]\n",
      "Get:18 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\n",
      "Get:19 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [32.9 kB]\n",
      "Get:20 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1270 kB]\n",
      "Get:21 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3209 kB]\n",
      "Get:22 http://security.ubuntu.com/ubuntu jammy-security/multiverse amd64 Packages [48.5 kB]\n",
      "Fetched 42.6 MB in 2s (21.2 MB/s)                            \n",
      "Reading package lists... Done\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "Suggested packages:\n",
      "  zip\n",
      "The following NEW packages will be installed:\n",
      "  unzip\n",
      "0 upgraded, 1 newly installed, 0 to remove and 143 not upgraded.\n",
      "Need to get 175 kB of archives.\n",
      "After this operation, 386 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 unzip amd64 6.0-26ubuntu3.2 [175 kB]\n",
      "Fetched 175 kB in 0s (2226 kB/s)\n",
      "debconf: delaying package configuration, since apt-utils is not installed\n",
      "Selecting previously unselected package unzip.\n",
      "(Reading database ... 20729 files and directories currently installed.)\n",
      "Preparing to unpack .../unzip_6.0-26ubuntu3.2_amd64.deb ...\n",
      "Unpacking unzip (6.0-26ubuntu3.2) ...\n",
      "Setting up unzip (6.0-26ubuntu3.2) ...\n"
     ]
    }
   ],
   "source": [
    "# To make the unzip command below work \n",
    "!apt-get update && apt-get install -y unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ad644d-aedd-4749-94c3-a34e87f9744b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell: Prepare Split TinyImageNet tasks for SFAO (CNN) ===\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset, TensorDataset\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "!wget http://cs231n.stanford.edu/tiny-imagenet-200.zip\n",
    "!unzip -q /workspace/tiny-imagenet-200.zip -d /workspace/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b1b021-a58f-410b-87eb-4aad3c7593b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.listdir('/workspace/tiny-imagenet-200'))\n",
    "print(os.listdir('/workspace/tiny-imagenet-200/train'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7ce9d5e-fce2-465b-9154-e673dee3471b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 28\u001b[0m\n\u001b[1;32m     20\u001b[0m test_transform \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[1;32m     21\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mResize((\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m64\u001b[39m)),\n\u001b[1;32m     22\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mToTensor(),\n\u001b[1;32m     23\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mNormalize(mean\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.4802\u001b[39m, \u001b[38;5;241m0.4481\u001b[39m, \u001b[38;5;241m0.3975\u001b[39m],\n\u001b[1;32m     24\u001b[0m                          std\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.2770\u001b[39m, \u001b[38;5;241m0.2691\u001b[39m, \u001b[38;5;241m0.2821\u001b[39m])\n\u001b[1;32m     25\u001b[0m ])\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# ===== Load datasets =====\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m train_ds \u001b[38;5;241m=\u001b[39m datasets\u001b[38;5;241m.\u001b[39mImageFolder(\u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(root, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m), transform\u001b[38;5;241m=\u001b[39mtrain_transform)\n\u001b[1;32m     29\u001b[0m val_ds   \u001b[38;5;241m=\u001b[39m datasets\u001b[38;5;241m.\u001b[39mImageFolder(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(root, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m), transform\u001b[38;5;241m=\u001b[39mtest_transform)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Map original class indices to sequential 0..199\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "# ===== Settings =====\n",
    "root = '/workspace/tiny-imagenet-200' \n",
    "num_tasks = 10\n",
    "num_classes = 200\n",
    "classes_per_task = num_classes // num_tasks  # 20 per task\n",
    "batch_size = 64\n",
    "num_epochs = 2\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# ===== Transforms =====\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.RandomCrop(64, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.4802, 0.4481, 0.3975],\n",
    "                         std=[0.2770, 0.2691, 0.2821])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.4802, 0.4481, 0.3975],\n",
    "                         std=[0.2770, 0.2691, 0.2821])\n",
    "])\n",
    "\n",
    "# ===== Load datasets =====\n",
    "train_ds = datasets.ImageFolder(os.path.join(root, 'train'), transform=train_transform)\n",
    "val_ds   = datasets.ImageFolder(os.path.join(root, 'val'), transform=test_transform)\n",
    "\n",
    "# Map original class indices to sequential 0..199\n",
    "class_to_idx = train_ds.class_to_idx\n",
    "sorted_classes = sorted(class_to_idx.keys())\n",
    "class_mapping = {class_to_idx[c]: i for i, c in enumerate(sorted_classes)}\n",
    "\n",
    "train_labels = [class_mapping[label] for _, label in train_ds.samples]\n",
    "val_labels   = [class_mapping[label] for _, label in val_ds.samples]\n",
    "\n",
    "# Helper: get subset dataset for a class list\n",
    "def subset_by_classes(dataset, labels, class_list):\n",
    "    idxs = [i for i, lab in enumerate(labels) if lab in class_list]\n",
    "    return Subset(dataset, idxs)\n",
    "\n",
    "# ===== Create tasks =====\n",
    "train_tasks, test_tasks = [], []\n",
    "for t in range(num_tasks):\n",
    "    cls_start = t * classes_per_task\n",
    "    cls_end = cls_start + classes_per_task\n",
    "    task_classes = list(range(cls_start, cls_end))\n",
    "    train_tasks.append(subset_by_classes(train_ds, train_labels, task_classes))\n",
    "    test_tasks.append(subset_by_classes(val_ds, val_labels, task_classes))\n",
    "    print(f\"Task {t}: Classes {cls_start}-{cls_end-1} | Train: {len(train_tasks[-1])}, Test: {len(test_tasks[-1])}\")\n",
    "\n",
    "# ===== Simple CNN for TinyImageNet =====\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TinyImageNetCNN(nn.Module):\n",
    "    def __init__(self, num_outputs=20):  # default per task\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(256 * 8 * 8, 512)\n",
    "        self.fc2 = nn.Linear(512, num_outputs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # 64x32x32\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # 128x16x16\n",
    "        x = self.pool(F.relu(self.conv3(x)))  # 256x8x8\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n",
    "\n",
    "# ===== SFAO setup =====\n",
    "class SFAO:\n",
    "    def __init__(self, model, lr=0.01, device='cuda'):\n",
    "        self.model = model.to(device)\n",
    "        self.lr = lr\n",
    "        self.device = device\n",
    "        self.optimizer = optim.SGD(self.model.parameters(), lr=lr)\n",
    "        self.S = []  # Memory of gradient directions from previous tasks\n",
    "\n",
    "    def _flatten_grad(self):\n",
    "        return torch.cat([p.grad.view(-1) for p in self.model.parameters() if p.grad is not None])\n",
    "\n",
    "    def _assign_grad(self, flat_grad):\n",
    "        idx = 0\n",
    "        for p in self.model.parameters():\n",
    "            if p.grad is not None:\n",
    "                numel = p.numel()\n",
    "                p.grad.copy_(flat_grad[idx: idx+numel].view_as(p))\n",
    "                idx += numel\n",
    "\n",
    "    def _project_grad(self, g):\n",
    "        if len(self.S) == 0:\n",
    "            return g\n",
    "        g_proj = g.clone()\n",
    "        for v in self.S:\n",
    "            proj = (torch.dot(g_proj, v) / torch.dot(v, v)) * v\n",
    "            g_proj -= proj\n",
    "        return g_proj\n",
    "\n",
    "    # [Added method] Compute max cosine similarity between gradient g and sampled stored gradients\n",
    "    def _cosine_similarity(self, sample, g):\n",
    "        if len(sample) == 0:\n",
    "            return 1.0\n",
    "        max_sim = 0\n",
    "        for v in sample:\n",
    "            sim = torch.dot(g, v) / (torch.norm(g) * torch.norm(v))\n",
    "            if sim > max_sim:\n",
    "                max_sim = sim\n",
    "        return max_sim\n",
    "\n",
    "    # [Added method] Monte Carlo sample k gradients from stored memory without replacement\n",
    "    def _monte_carlo(self, k):\n",
    "        if len(self.S) <= k:\n",
    "            return self.S\n",
    "        else:\n",
    "            return random.sample(self.S, k)\n",
    "\n",
    "    # [Updated method] Selective projection based on cosine similarity threshold\n",
    "    def observe(self, x, y, criterion=nn.CrossEntropyLoss(), threshold=0.80, sample_size=10):\n",
    "        self.model.train()\n",
    "        x, y = x.to(self.device), y.to(self.device)\n",
    "        self.optimizer.zero_grad()\n",
    "        out = self.model(x)\n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()\n",
    "\n",
    "        g = self._flatten_grad()\n",
    "        sample = self._monte_carlo(sample_size)\n",
    "        max_sim = self._cosine_similarity(sample, g)\n",
    "\n",
    "        if max_sim < threshold:\n",
    "            g_orth = self._project_grad(g)\n",
    "            self._assign_grad(g_orth)\n",
    "        else:\n",
    "            self._assign_grad(g)\n",
    "\n",
    "        self.optimizer.step()\n",
    "        return loss.item()\n",
    "\n",
    "    def end_task(self, dataloader, criterion=nn.CrossEntropyLoss()):\n",
    "        self.model.eval()\n",
    "        for x, y in dataloader:\n",
    "            x, y = x.to(self.device), y.to(self.device)\n",
    "            self.model.zero_grad()\n",
    "            out = self.model(x)\n",
    "            loss = criterion(out, y)\n",
    "            loss.backward()\n",
    "\n",
    "            u = self._flatten_grad()\n",
    "            u_proj = self._project_grad(u)\n",
    "            norm_u_proj = u_proj / (u_proj.norm() + 1e-10)\n",
    "            self.S.append(norm_u_proj.detach().clone())\n",
    "            \n",
    "accuracy_matrix = np.zeros((num_tasks, num_tasks))\n",
    "sfao = SFAO(TinyImageNetCNN(classes_per_task), lr=0.01, device=device)\n",
    "\n",
    "def evaluate_task(model, dataloader):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            preds = model(x).argmax(dim=1)\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += y.size(0)\n",
    "    return correct / total\n",
    "\n",
    "# ===== Training loop =====\n",
    "for task_id, train_dataset in enumerate(train_tasks):\n",
    "    print(f\"\\n=== Training Task {task_id+1} ===\")\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0.0\n",
    "        for x, y in tqdm(train_loader):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            epoch_loss += sfao.observe(x, y)\n",
    "        print(f\"Epoch {epoch+1}, Loss: {epoch_loss/len(train_loader):.4f}\")\n",
    "\n",
    "    # Evaluate on all seen tasks\n",
    "    for eval_id in range(task_id+1):\n",
    "        test_loader = DataLoader(test_tasks[eval_id], batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "        acc = evaluate_task(sfao.model, test_loader)\n",
    "        accuracy_matrix[task_id, eval_id] = acc\n",
    "        print(f\"Accuracy on Task {eval_id+1}: {acc:.3f}\")\n",
    "\n",
    "    sfao.end_task(train_loader)\n",
    "\n",
    "# ===== Metrics =====\n",
    "ACC = accuracy_matrix[-1].mean()\n",
    "F = np.mean([np.max(accuracy_matrix[:num_tasks-1, j]) - accuracy_matrix[-1, j] for j in range(num_tasks-1)]) if num_tasks>1 else 0.0\n",
    "BWT = np.mean([accuracy_matrix[-1, j] - accuracy_matrix[j, j] for j in range(num_tasks-1)]) if num_tasks>1 else 0.0\n",
    "FWT = np.mean([accuracy_matrix[i, i+1] for i in range(num_tasks-1)]) if num_tasks>1 else 0.0\n",
    "\n",
    "num_params = sum(p.numel() for p in sfao.model.parameters())\n",
    "mem_usage = len(sfao.S) * num_params * 4 / (1024**2)\n",
    "PSM = 0.5*(1-F) + 0.5*max(FWT,0)\n",
    "\n",
    "print(\"=== Metrics (Split TinyImageNet) ===\")\n",
    "print(f\"ACC={ACC:.4f}, F={F:.4f}, BWT={BWT:.4f}, FWT={FWT:.4f}, Mem={mem_usage:.2f}MB, PSM={PSM:.4f}\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.imshow(accuracy_matrix, cmap='viridis', interpolation='nearest')\n",
    "plt.colorbar(label='Accuracy')\n",
    "plt.xlabel('Evaluation Task')\n",
    "plt.ylabel('Training Task')\n",
    "plt.title('SFAO Accuracy Matrix (Split TinyImageNet)')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
