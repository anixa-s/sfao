{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a93bcf43-a0f5-4d6a-a15c-0057729197ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.6-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.24.1)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.16.0+cu118)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.59.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (109 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.7/109.7 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.9-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: torch==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.1.0+cu118)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (4.4.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (2023.4.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (2.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2022.12.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.0->torchvision) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0->torchvision) (1.3.0)\n",
      "Downloading matplotlib-3.10.6-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m199.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.0/325.0 kB\u001b[0m \u001b[31m125.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.59.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (4.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m254.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.9-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m204.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tqdm, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.2 cycler-0.12.1 fonttools-4.59.2 kiwisolver-1.4.9 matplotlib-3.10.6 tqdm-4.67.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib numpy torchvision tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4689652-63ba-4456-8006-2198b51fde08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Task 0: classes 0..9 | train 5000, test 1000\n",
      "Task 1: classes 10..19 | train 5000, test 1000\n",
      "Task 2: classes 20..29 | train 5000, test 1000\n",
      "Task 3: classes 30..39 | train 5000, test 1000\n",
      "Task 4: classes 40..49 | train 5000, test 1000\n",
      "Task 5: classes 50..59 | train 5000, test 1000\n",
      "Task 6: classes 60..69 | train 5000, test 1000\n",
      "Task 7: classes 70..79 | train 5000, test 1000\n",
      "Task 8: classes 80..89 | train 5000, test 1000\n",
      "Task 9: classes 90..99 | train 5000, test 1000\n",
      "\n",
      "=== Task 1/10 | classes 0..9 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task 1 Epoch 1: 100%|██████████| 157/157 [00:07<00:00, 19.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: loss=1.9256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task 1 Epoch 2: 100%|██████████| 157/157 [00:06<00:00, 22.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: loss=1.5942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Task 1: 0.506\n",
      "[OGD] Harvested 30 dirs (seen 30 batches). Memory size: 30\n",
      "\n",
      "=== Task 2/10 | classes 10..19 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task 2 Epoch 1: 100%|██████████| 157/157 [00:09<00:00, 16.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: loss=1.8596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task 2 Epoch 2: 100%|██████████| 157/157 [00:09<00:00, 16.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: loss=1.4806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Task 1: 0.119\n",
      "Accuracy on Task 2: 0.517\n",
      "[OGD] Harvested 30 dirs (seen 30 batches). Memory size: 60\n",
      "\n",
      "=== Task 3/10 | classes 20..29 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task 3 Epoch 1: 100%|██████████| 157/157 [00:12<00:00, 12.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: loss=1.6873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task 3 Epoch 2: 100%|██████████| 157/157 [00:12<00:00, 12.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: loss=1.2760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Task 1: 0.157\n",
      "Accuracy on Task 2: 0.122\n",
      "Accuracy on Task 3: 0.560\n",
      "[OGD] Harvested 30 dirs (seen 30 batches). Memory size: 90\n",
      "\n",
      "=== Task 4/10 | classes 30..39 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task 4 Epoch 1: 100%|██████████| 157/157 [00:14<00:00, 10.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: loss=1.6177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task 4 Epoch 2: 100%|██████████| 157/157 [00:14<00:00, 10.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: loss=1.2175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Task 1: 0.071\n",
      "Accuracy on Task 2: 0.160\n",
      "Accuracy on Task 3: 0.122\n",
      "Accuracy on Task 4: 0.607\n",
      "[OGD] Harvested 30 dirs (seen 30 batches). Memory size: 120\n",
      "\n",
      "=== Task 5/10 | classes 40..49 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task 5 Epoch 1: 100%|██████████| 157/157 [00:17<00:00,  9.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: loss=1.4118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task 5 Epoch 2: 100%|██████████| 157/157 [00:17<00:00,  9.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: loss=1.0027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Task 1: 0.126\n",
      "Accuracy on Task 2: 0.111\n",
      "Accuracy on Task 3: 0.085\n",
      "Accuracy on Task 4: 0.159\n",
      "Accuracy on Task 5: 0.673\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.25 GiB. GPU 0 has a total capacty of 44.45 GiB of which 20.05 GiB is free. Process 2969108 has 24.39 GiB memory in use. Of the allocated memory 20.82 GiB is allocated by PyTorch, and 3.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 385\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy on Task \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mj\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;66;03m# Grow OGD memory from current task data\u001b[39;00m\n\u001b[0;32m--> 385\u001b[0m     \u001b[43mogd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirs_to_add\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdirs_per_task\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mharvest_batches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mharvest_batches\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;66;03m# Compute Continual Learning Metrics\u001b[39;00m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;66;03m# Average Accuracy (ACC)\u001b[39;00m\n\u001b[1;32m    390\u001b[0m ACC \u001b[38;5;241m=\u001b[39m accuracy_matrix[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()  \u001b[38;5;66;03m# Final row averaged across tasks\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 310\u001b[0m, in \u001b[0;36mOGD.end_task\u001b[0;34m(self, dataloader, dirs_to_add, harvest_batches)\u001b[0m\n\u001b[1;32m    307\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    309\u001b[0m     g \u001b[38;5;241m=\u001b[39m flatten_grads(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel)\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_add_dir_to_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    311\u001b[0m     added \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[OGD] Harvested \u001b[39m\u001b[38;5;132;01m{\u001b[39;00madded\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m dirs (seen \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseen\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m batches). \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    314\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMemory size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;241m0\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemory\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01mis\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemory\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 267\u001b[0m, in \u001b[0;36mOGD._add_dir_to_memory\u001b[0;34m(self, g)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemory\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_mem_dirs:\n\u001b[0;32m--> 267\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemory \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmemory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mg\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    269\u001b[0m         \u001b[38;5;66;03m# Replace a random row to maintain diversity (FIFO/random policy)\u001b[39;00m\n\u001b[1;32m    270\u001b[0m         idx \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemory\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), (\u001b[38;5;241m1\u001b[39m,))\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.25 GiB. GPU 0 has a total capacty of 44.45 GiB of which 20.05 GiB is free. Process 2969108 has 24.39 GiB memory in use. Of the allocated memory 20.82 GiB is allocated by PyTorch, and 3.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# ================================================\n",
    "# OGD on Split CIFAR-100 (10 tasks × 10 classes)\n",
    "# ================================================\n",
    "# - Memory-efficient task construction\n",
    "# - OGD with orthonormal gradient memory\n",
    "# - Stores optimizer/criterion in OGD\n",
    "# - Accuracy matrix + CL metrics + plot\n",
    "# ================================================\n",
    "\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -----------------\n",
    "# Repro & Device\n",
    "# -----------------\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# -----------------\n",
    "# Hyperparameters\n",
    "# -----------------\n",
    "root = \"./data\"\n",
    "num_tasks = 10\n",
    "num_classes = 100\n",
    "classes_per_task = num_classes // num_tasks  # 10\n",
    "batch_size = 32\n",
    "num_epochs = 2\n",
    "download = True\n",
    "\n",
    "# Optimizer/loss\n",
    "learning_rate = 0.001\n",
    "weight_decay = 5e-4\n",
    "momentum = 0.9\n",
    "\n",
    "# OGD memory\n",
    "max_mem_dirs = 1000    # cap on number of stored gradient directions (global)\n",
    "dirs_per_task = 120   # target number of new directions to add per task\n",
    "harvest_batches = 30  # batches to sample for memory after each task\n",
    "grad_eps = 1e-6       # min norm to accept a direction\n",
    "\n",
    "# -----------------\n",
    "# Transforms\n",
    "# -----------------\n",
    "normalize = transforms.Normalize(mean=(0.5071, 0.4867, 0.4408),\n",
    "                                 std=(0.2675, 0.2565, 0.2761))\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "\n",
    "# -----------------\n",
    "# Datasets\n",
    "# -----------------\n",
    "train_full = datasets.CIFAR100(root=root, train=True,  download=download, transform=train_transform)\n",
    "test_full  = datasets.CIFAR100(root=root, train=False, download=download, transform=test_transform)\n",
    "\n",
    "train_targets = np.array(train_full.targets)\n",
    "test_targets  = np.array(test_full.targets)\n",
    "\n",
    "# -----------------\n",
    "# Task splits (indices & class lists)\n",
    "# -----------------\n",
    "task_class_lists = []\n",
    "train_indices_per_task, test_indices_per_task = [], []\n",
    "\n",
    "for t in range(num_tasks):\n",
    "    cls_start = t * classes_per_task\n",
    "    cls_end = cls_start + classes_per_task\n",
    "    task_classes = list(range(cls_start, cls_end))\n",
    "    task_class_lists.append(task_classes)\n",
    "\n",
    "    train_idx = np.where(np.isin(train_targets, task_classes))[0].tolist()\n",
    "    test_idx  = np.where(np.isin(test_targets,  task_classes))[0].tolist()\n",
    "\n",
    "    train_indices_per_task.append(train_idx)\n",
    "    test_indices_per_task.append(test_idx)\n",
    "\n",
    "    print(f\"Task {t}: classes {task_classes[0]}..{task_classes[-1]} | \"\n",
    "          f\"train {len(train_idx)}, test {len(test_idx)}\")\n",
    "\n",
    "# -----------------\n",
    "# Per-task label mapping dataset\n",
    "# -----------------\n",
    "class MapLabelsDataset(Dataset):\n",
    "    def __init__(self, base_dataset, indices, class_map):\n",
    "        self.base = base_dataset\n",
    "        self.indices = indices\n",
    "        self.class_map = class_map\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        x, y = self.base[self.indices[i]]\n",
    "        return x, self.class_map[int(y)]\n",
    "\n",
    "# -----------------\n",
    "# WideResNet (WRN-28-10)\n",
    "# -----------------\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, stride):\n",
    "        super().__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.conv1 = nn.Conv2d(in_planes, out_planes, 3, stride, 1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_planes)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_planes, out_planes, 3, 1, 1, bias=False)\n",
    "        self.equalInOut = (in_planes == out_planes)\n",
    "        self.convShortcut = None if self.equalInOut else nn.Conv2d(\n",
    "            in_planes, out_planes, 1, stride, 0, bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.relu1(self.bn1(x))\n",
    "        shortcut = x if self.equalInOut else self.convShortcut(x)\n",
    "        out = self.conv1(out)\n",
    "        out = self.relu2(self.bn2(out))\n",
    "        out = self.conv2(out)\n",
    "        return out + shortcut\n",
    "\n",
    "class NetworkBlock(nn.Module):\n",
    "    def __init__(self, n, in_planes, out_planes, block, stride):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        for i in range(n):\n",
    "            layers.append(\n",
    "                block(in_planes if i == 0 else out_planes,\n",
    "                      out_planes,\n",
    "                      stride if i == 0 else 1)\n",
    "            )\n",
    "        self.layer = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer(x)\n",
    "\n",
    "class WideResNet(nn.Module):\n",
    "    def __init__(self, depth=28, widen_factor=10, num_classes=10):\n",
    "        super().__init__()\n",
    "        assert (depth - 4) % 6 == 0\n",
    "        n = (depth - 4) // 6\n",
    "        k = widen_factor\n",
    "        nChannels = [16, 16*k, 32*k, 64*k]\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, nChannels[0], 3, 1, 1, bias=False)\n",
    "        self.block1 = NetworkBlock(n, nChannels[0], nChannels[1], BasicBlock, 1)\n",
    "        self.block2 = NetworkBlock(n, nChannels[1], nChannels[2], BasicBlock, 2)\n",
    "        self.block3 = NetworkBlock(n, nChannels[2], nChannels[3], BasicBlock, 2)\n",
    "        self.bn = nn.BatchNorm2d(nChannels[3])\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc = nn.Linear(nChannels[3], num_classes)\n",
    "        self.nChannels = nChannels[3]\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.relu(self.bn(x))\n",
    "        x = F.adaptive_avg_pool2d(x, 1).view(-1, self.nChannels)\n",
    "        return self.fc(x)\n",
    "\n",
    "\"\"\"\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 256)\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))   # 32x16x16\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))   # 64x8x8\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))   # 128x4x4\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n",
    "\"\"\"\n",
    "\n",
    "# -----------------\n",
    "# Utils to flatten/assign grads\n",
    "# -----------------\n",
    "def flatten_grads(model):\n",
    "    parts = []\n",
    "    for p in model.parameters():\n",
    "        if p.requires_grad and p.grad is not None:\n",
    "            parts.append(p.grad.view(-1))\n",
    "    return torch.cat(parts) if parts else torch.tensor([], device=next(model.parameters()).device)\n",
    "\n",
    "def assign_grads_from_vector(model, grad_vec):\n",
    "    offset = 0\n",
    "    for p in model.parameters():\n",
    "        if not p.requires_grad:\n",
    "            continue\n",
    "        n = p.numel()\n",
    "        if p.grad is None:\n",
    "            p.grad = torch.zeros_like(p)\n",
    "        p.grad.copy_(grad_vec[offset:offset+n].view_as(p))\n",
    "        offset += n\n",
    "\n",
    "# -----------------\n",
    "# OGD (Option 2: stores optimizer & criterion internally)\n",
    "# -----------------\n",
    "class OGD:\n",
    "    def __init__(self, model, optimizer, criterion, device,\n",
    "                 max_mem_dirs=1000, grad_eps=1e-6):\n",
    "        self.model = model.to(device)\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "        self.device = device\n",
    "        self.P = sum(p.numel() for p in self.model.parameters() if p.requires_grad)\n",
    "        self.memory = None   # [k, P], orthonormal rows (unit-norm)\n",
    "        self.max_mem_dirs = max_mem_dirs\n",
    "        self.grad_eps = grad_eps\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _project_onto_complement(self, g):\n",
    "        # g: [P]\n",
    "        if self.memory is None or self.memory.size(0) == 0:\n",
    "            return g\n",
    "        # Memory rows are orthonormal ⇒ projection is g_perp = g - M^T (M g)\n",
    "        Mg = torch.mv(self.memory, g)            # [k]\n",
    "        g_perp = g - torch.mv(self.memory.t(), Mg)\n",
    "        return g_perp\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _add_dir_to_memory(self, g):\n",
    "        # Gram-Schmidt orth against existing memory; if large enough, normalize & append\n",
    "        if self.memory is not None and self.memory.size(0) > 0:\n",
    "            Mg = torch.mv(self.memory, g)\n",
    "            g = g - torch.mv(self.memory.t(), Mg)\n",
    "        norm = torch.linalg.norm(g)\n",
    "        if norm > self.grad_eps:\n",
    "            g = g / norm\n",
    "            if self.memory is None:\n",
    "                self.memory = g.unsqueeze(0)\n",
    "            else:\n",
    "                if self.memory.size(0) < self.max_mem_dirs:\n",
    "                    self.memory = torch.vstack([self.memory, g])\n",
    "                else:\n",
    "                    # Replace a random row to maintain diversity (FIFO/random policy)\n",
    "                    idx = torch.randint(0, self.memory.size(0), (1,)).item()\n",
    "                    self.memory[idx] = g\n",
    "\n",
    "    def observe(self, x, y):\n",
    "        \"\"\"One OGD training step on a batch.\"\"\"\n",
    "        self.model.train()\n",
    "        x, y = x.to(self.device), y.to(self.device)\n",
    "\n",
    "        self.optimizer.zero_grad(set_to_none=True)\n",
    "        logits = self.model(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        loss.backward()\n",
    "\n",
    "        # Flatten grads → project → assign → step\n",
    "        g = flatten_grads(self.model).detach()\n",
    "        g_perp = self._project_onto_complement(g)\n",
    "        assign_grads_from_vector(self.model, g_perp)\n",
    "        self.optimizer.step()\n",
    "        return loss.item()\n",
    "\n",
    "    def end_task(self, dataloader, dirs_to_add=100, harvest_batches=30):\n",
    "        \"\"\"Harvest gradient directions (from current task) to expand memory.\"\"\"\n",
    "        self.model.train()\n",
    "        for p in self.model.parameters():\n",
    "            p.requires_grad_(True)\n",
    "        torch.set_grad_enabled(True)\n",
    "\n",
    "        added, seen = 0, 0\n",
    "        for xb, yb in dataloader:\n",
    "            if seen >= harvest_batches or added >= dirs_to_add:\n",
    "                break\n",
    "            seen += 1\n",
    "\n",
    "            xb, yb = xb.to(self.device), yb.to(self.device)\n",
    "            self.model.zero_grad(set_to_none=True)\n",
    "            logits = self.model(xb)\n",
    "            loss = self.criterion(logits, yb)\n",
    "            loss.backward()\n",
    "\n",
    "            g = flatten_grads(self.model).detach()\n",
    "            self._add_dir_to_memory(g)\n",
    "            added += 1\n",
    "\n",
    "        print(f\"[OGD] Harvested {added} dirs (seen {seen} batches). \"\n",
    "              f\"Memory size: {0 if self.memory is None else self.memory.size(0)}\")\n",
    "\n",
    "# -----------------\n",
    "# Eval\n",
    "# -----------------\n",
    "@torch.no_grad()\n",
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    for xb, yb in dataloader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        preds = model(xb).argmax(1)\n",
    "        correct += (preds == yb).sum().item()\n",
    "        total += yb.size(0)\n",
    "    return correct / max(1, total)\n",
    "\n",
    "# -----------------\n",
    "# Init model/optimizer/criterion/OGD\n",
    "# -----------------\n",
    "\"\"\"\n",
    "model = SimpleCNN(num_classes=classes_per_task).to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum, weight_decay=weight_decay)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "ogd = OGD(model, optimizer, criterion, device,\n",
    "          max_mem_dirs=max_mem_dirs, grad_eps=grad_eps)\n",
    "\"\"\"\n",
    "\n",
    "# -----------------\n",
    "# Init model/optimizer/criterion/OGD\n",
    "# -----------------\n",
    "model = WideResNet(depth=28, widen_factor=10, num_classes=classes_per_task).to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate,\n",
    "                            momentum=momentum, weight_decay=weight_decay)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "ogd = OGD(model, optimizer, criterion, device,\n",
    "          max_mem_dirs=max_mem_dirs, grad_eps=grad_eps)\n",
    "\n",
    "# -----------------\n",
    "# Train across tasks\n",
    "# -----------------\n",
    "accuracy_matrix = np.zeros((num_tasks, num_tasks), dtype=np.float32)\n",
    "\n",
    "loader_kwargs = dict(num_workers=2, pin_memory=True) if device.type == \"cuda\" else dict(num_workers=0)\n",
    "\n",
    "for t in range(num_tasks):\n",
    "    # Datasets & loaders for task t (labels remapped to 0..9)\n",
    "    class_map = {orig: i for i, orig in enumerate(task_class_lists[t])}\n",
    "    train_ds_t = MapLabelsDataset(train_full, train_indices_per_task[t], class_map)\n",
    "    test_ds_t  = MapLabelsDataset(test_full,  test_indices_per_task[t],  class_map)\n",
    "\n",
    "    train_loader = DataLoader(train_ds_t, batch_size=batch_size, shuffle=True,  **loader_kwargs)\n",
    "    test_loader  = DataLoader(test_ds_t,  batch_size=batch_size, shuffle=False, **loader_kwargs)\n",
    "\n",
    "    print(f\"\\n=== Task {t+1}/{num_tasks} | classes {task_class_lists[t][0]}..{task_class_lists[t][-1]} ===\")\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        running = 0.0\n",
    "        for xb, yb in tqdm(train_loader, desc=f\"Task {t+1} Epoch {epoch}\"):\n",
    "            running += ogd.observe(xb, yb)\n",
    "        print(f\"Epoch {epoch}: loss={running/len(train_loader):.4f}\")\n",
    "\n",
    "    # Evaluate on all seen tasks so far\n",
    "    for j in range(t + 1):\n",
    "        class_map_eval = {orig: i for i, orig in enumerate(task_class_lists[j])}\n",
    "        test_ds_eval = MapLabelsDataset(test_full, test_indices_per_task[j], class_map_eval)\n",
    "        test_loader_eval = DataLoader(test_ds_eval, batch_size=batch_size, shuffle=False, **loader_kwargs)\n",
    "        acc = evaluate(ogd.model, test_loader_eval, device)\n",
    "        accuracy_matrix[t, j] = acc\n",
    "        print(f\"Accuracy on Task {j+1}: {acc:.3f}\")\n",
    "\n",
    "    # Grow OGD memory from current task data\n",
    "    ogd.end_task(train_loader, dirs_to_add=dirs_per_task, harvest_batches=harvest_batches)\n",
    "\n",
    "\n",
    "# Compute Continual Learning Metrics\n",
    "# Average Accuracy (ACC)\n",
    "ACC = accuracy_matrix[-1].mean()  # Final row averaged across tasks\n",
    "\n",
    "# Average Forgetting (F)\n",
    "F = np.mean([\n",
    "    np.max(accuracy_matrix[:num_tasks-1, j]) - accuracy_matrix[-1, j]\n",
    "    for j in range(num_tasks-1)\n",
    "])\n",
    "\n",
    "# Backward Transfer (BWT)\n",
    "BWT = np.mean([\n",
    "    accuracy_matrix[-1, j] - accuracy_matrix[j, j]\n",
    "    for j in range(num_tasks-1)\n",
    "])\n",
    "\n",
    "# Forward Transfer (FWT)\n",
    "# Measures how much previous tasks helped the next task before it was trained\n",
    "FWT = np.mean([\n",
    "    accuracy_matrix[i, i+1]\n",
    "    for i in range(num_tasks-1)\n",
    "])\n",
    "\n",
    "# Memory Usage (in MB)\n",
    "num_params = sum(p.numel() for p in ogd.model.parameters())\n",
    "dirs_count = 0 if ogd.memory is None else ogd.memory.size(0)\n",
    "mem_usage = dirs_count * num_params * 4 / (1024**2)  # 4 bytes per float32\n",
    "\n",
    "# Computation Cost (approximate as #dirs, since each step projects on memory)\n",
    "comp_cost = dirs_count\n",
    "\n",
    "# Plasticity-Stability Measure (PSM) - Normalized 0 to 1\n",
    "\n",
    "# Define components\n",
    "stability = 1 - F                 # High if forgetting is low\n",
    "plasticity = max(FWT, 0)          # High if positive forward transfer\n",
    "\n",
    "alpha = 0.5                       # Balance between stability and plasticity\n",
    "PSM = alpha * stability + (1 - alpha) * plasticity\n",
    "\n",
    "# Print Metrics\n",
    "print(\"=== Continual Learning Metrics ===\")\n",
    "print(f\"Average Accuracy (ACC):       {ACC:.4f}\")\n",
    "print(f\"Forgetting (F):              {F:.4f}\")\n",
    "print(f\"Backward Transfer (BWT):     {BWT:.4f}\")\n",
    "print(f\"Forward Transfer (FWT):      {FWT:.4f}\")\n",
    "print(f\"Memory Usage:                {mem_usage:.2f} MB\")\n",
    "print(f\"Computation Cost:            {comp_cost} projections/batch\")\n",
    "print(f\"Plasticity-Stability Measure (PSM): {PSM:.4f} (0-1 normalized)\")\n",
    "\n",
    "print(\"=== Metrics (Split CIFAR-100) ===\")\n",
    "print(f\"ACC={ACC:.4f}, F={F:.4f}, BWT={BWT:.4f}, FWT={FWT:.4f}, Mem={mem_usage:.2f}MB, PSM={PSM:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.imshow(accuracy_matrix, cmap='viridis', interpolation='nearest')\n",
    "plt.colorbar(label='Accuracy')\n",
    "plt.xlabel('Evaluation Task')\n",
    "plt.ylabel('Training Task')\n",
    "plt.title('OGD Accuracy Matrix (Split CIFAR-100)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1314533b-7c2a-4f4a-ae62-53d368dae59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Task 0: classes 0-1, train=10000, test=2000\n",
      "Task 1: classes 2-3, train=10000, test=2000\n",
      "Task 2: classes 4-5, train=10000, test=2000\n",
      "Task 3: classes 6-7, train=10000, test=2000\n",
      "Task 4: classes 8-9, train=10000, test=2000\n",
      "Prepared 5 tasks (Split CIFAR-10)\n",
      "\n",
      "=== Training Task 1 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:15<00:00, 20.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss=0.3703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:15<00:00, 20.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss=0.2434\n",
      "Accuracy on Task 1: 0.871\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 140.00 MiB. GPU 0 has a total capacty of 44.45 GiB of which 14.62 MiB is free. Process 2307347 has 44.43 GiB memory in use. Of the allocated memory 41.47 GiB is allocated by PyTorch, and 2.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 250\u001b[0m\n\u001b[1;32m    247\u001b[0m         accuracy_matrix[task_id, eval_id] \u001b[38;5;241m=\u001b[39m acc\n\u001b[1;32m    248\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy on Task \u001b[39m\u001b[38;5;132;01m{\u001b[39;00meval_id\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 250\u001b[0m     \u001b[43mogd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;66;03m# === Metrics ===\u001b[39;00m\n\u001b[1;32m    253\u001b[0m ACC \u001b[38;5;241m=\u001b[39m accuracy_matrix[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\n",
      "Cell \u001b[0;32mIn[4], line 205\u001b[0m, in \u001b[0;36mOGD.end_task\u001b[0;34m(self, dataloader)\u001b[0m\n\u001b[1;32m    203\u001b[0m loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcross_entropy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(x), y)\n\u001b[1;32m    204\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m--> 205\u001b[0m g \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m grads\u001b[38;5;241m.\u001b[39mappend(g \u001b[38;5;241m/\u001b[39m g\u001b[38;5;241m.\u001b[39mnorm())\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(grads) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmem_size:\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 140.00 MiB. GPU 0 has a total capacty of 44.45 GiB of which 14.62 MiB is free. Process 2307347 has 44.43 GiB memory in use. Of the allocated memory 41.47 GiB is allocated by PyTorch, and 2.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# === Cell: prepare CIFAR-10 tasks for OGD (split) with CNN ===\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# === Hyperparameters ===\n",
    "root = './data'\n",
    "num_tasks = 5            \n",
    "num_classes = 10         \n",
    "classes_per_task = num_classes // num_tasks   # = 2\n",
    "batch_size = 32\n",
    "download = True\n",
    "num_epochs = 2\n",
    "learning_rate = 0.001\n",
    "mem_size = 200   # how many gradient directions to store per task\n",
    "\n",
    "# CIFAR-10 mean/std for normalization\n",
    "mean = torch.tensor([0.4914, 0.4822, 0.4465]).view(3, 1, 1)\n",
    "std = torch.tensor([0.2023, 0.1994, 0.2010]).view(3, 1, 1)\n",
    "\n",
    "# === Transforms ===\n",
    "train_transform = transforms.ToTensor()\n",
    "test_transform = transforms.ToTensor()\n",
    "\n",
    "# === Load datasets ===\n",
    "train_ds = datasets.CIFAR10(root=root, train=True, download=download, transform=train_transform)\n",
    "test_ds = datasets.CIFAR10(root=root, train=False, download=download, transform=test_transform)\n",
    "\n",
    "# === Helper: extract subset tensors for a given set of class IDs ===\n",
    "def extract_subset_tensors(dataset, class_list):\n",
    "    targets = np.array(dataset.targets)\n",
    "    mask = np.isin(targets, class_list)\n",
    "    indices = np.nonzero(mask)[0].tolist()\n",
    "    imgs, labs = [], []\n",
    "    for i in indices:\n",
    "        img, lbl = dataset[i]\n",
    "        imgs.append(img)\n",
    "        labs.append(lbl)\n",
    "    return torch.stack(imgs), torch.tensor(labs, dtype=torch.long)\n",
    "\n",
    "# === Build tasks ===\n",
    "train_tasks, test_tasks = [], []\n",
    "for t in range(num_tasks):\n",
    "    cls_start = t * classes_per_task\n",
    "    cls_end = cls_start + classes_per_task\n",
    "    task_classes = list(range(cls_start, cls_end))\n",
    "\n",
    "    x_train, y_train = extract_subset_tensors(train_ds, task_classes)\n",
    "    x_test, y_test = extract_subset_tensors(test_ds, task_classes)\n",
    "\n",
    "    # Normalize\n",
    "    x_train = (x_train - mean) / std\n",
    "    x_test = (x_test - mean) / std\n",
    "\n",
    "    # Map labels to 0..(classes_per_task-1)\n",
    "    class_map = {orig: i for i, orig in enumerate(task_classes)}\n",
    "    y_train_mapped = torch.tensor([class_map[int(v)] for v in y_train])\n",
    "    y_test_mapped = torch.tensor([class_map[int(v)] for v in y_test])\n",
    "\n",
    "    train_tasks.append(TensorDataset(x_train, y_train_mapped))\n",
    "    test_tasks.append(TensorDataset(x_test, y_test_mapped))\n",
    "\n",
    "    print(f\"Task {t}: classes {task_classes[0]}-{task_classes[-1]}, train={len(x_train)}, test={len(x_test)}\")\n",
    "\n",
    "print(f\"Prepared {len(train_tasks)} tasks (Split CIFAR-10)\")\n",
    "\n",
    "\"\"\"\n",
    "# === CNN model ===\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=2):   # 2 classes per task\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 256)\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # 32x16x16\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # 64x8x8\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n",
    "\"\"\"\n",
    "\n",
    "# -----------------\n",
    "# WideResNet (WRN-28-10)\n",
    "# -----------------\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, stride):\n",
    "        super().__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.conv1 = nn.Conv2d(in_planes, out_planes, 3, stride, 1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_planes)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_planes, out_planes, 3, 1, 1, bias=False)\n",
    "        self.equalInOut = (in_planes == out_planes)\n",
    "        self.convShortcut = None if self.equalInOut else nn.Conv2d(\n",
    "            in_planes, out_planes, 1, stride, 0, bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.relu1(self.bn1(x))\n",
    "        shortcut = x if self.equalInOut else self.convShortcut(x)\n",
    "        out = self.conv1(out)\n",
    "        out = self.relu2(self.bn2(out))\n",
    "        out = self.conv2(out)\n",
    "        return out + shortcut\n",
    "\n",
    "class NetworkBlock(nn.Module):\n",
    "    def __init__(self, n, in_planes, out_planes, block, stride):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        for i in range(n):\n",
    "            layers.append(\n",
    "                block(in_planes if i == 0 else out_planes,\n",
    "                      out_planes,\n",
    "                      stride if i == 0 else 1)\n",
    "            )\n",
    "        self.layer = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer(x)\n",
    "\n",
    "class WideResNet(nn.Module):\n",
    "    def __init__(self, depth=28, widen_factor=10, num_classes=10):\n",
    "        super().__init__()\n",
    "        assert (depth - 4) % 6 == 0\n",
    "        n = (depth - 4) // 6\n",
    "        k = widen_factor\n",
    "        nChannels = [16, 16*k, 32*k, 64*k]\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, nChannels[0], 3, 1, 1, bias=False)\n",
    "        self.block1 = NetworkBlock(n, nChannels[0], nChannels[1], BasicBlock, 1)\n",
    "        self.block2 = NetworkBlock(n, nChannels[1], nChannels[2], BasicBlock, 2)\n",
    "        self.block3 = NetworkBlock(n, nChannels[2], nChannels[3], BasicBlock, 2)\n",
    "        self.bn = nn.BatchNorm2d(nChannels[3])\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc = nn.Linear(nChannels[3], num_classes)\n",
    "        self.nChannels = nChannels[3]\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.relu(self.bn(x))\n",
    "        x = F.adaptive_avg_pool2d(x, 1).view(-1, self.nChannels)\n",
    "        return self.fc(x)\n",
    "\n",
    "\n",
    "# === OGD class ===\n",
    "class OGD:\n",
    "    def __init__(self, model, lr=0.001, device=\"cpu\", mem_size=200):\n",
    "        self.model = model.to(device)\n",
    "        self.opt = optim.Adam(self.model.parameters(), lr=lr)\n",
    "        self.device = device\n",
    "        self.S = []  # stored gradient directions\n",
    "        self.mem_size = mem_size\n",
    "\n",
    "    def project(self, grad_vec):\n",
    "        if not self.S:\n",
    "            return grad_vec\n",
    "        proj_grad = grad_vec.clone()\n",
    "        for g in self.S:\n",
    "            proj_grad -= (proj_grad @ g) * g\n",
    "        return proj_grad\n",
    "\n",
    "    def observe(self, x, y):\n",
    "        self.model.train()\n",
    "        x, y = x.to(self.device), y.to(self.device)\n",
    "        self.opt.zero_grad()\n",
    "        loss = F.cross_entropy(self.model(x), y)\n",
    "        loss.backward()\n",
    "\n",
    "        grad_vec = torch.cat([p.grad.view(-1) for p in self.model.parameters()])\n",
    "        grad_proj = self.project(grad_vec)\n",
    "        idx = 0\n",
    "        for p in self.model.parameters():\n",
    "            numel = p.numel()\n",
    "            p.grad.copy_(grad_proj[idx:idx+numel].view_as(p))\n",
    "            idx += numel\n",
    "\n",
    "        self.opt.step()\n",
    "        return loss.item()\n",
    "\n",
    "    def end_task(self, dataloader):\n",
    "        self.model.eval()\n",
    "        grads = []\n",
    "        for x, y in dataloader:\n",
    "            x, y = x.to(self.device), y.to(self.device)\n",
    "            self.opt.zero_grad()\n",
    "            loss = F.cross_entropy(self.model(x), y)\n",
    "            loss.backward()\n",
    "            g = torch.cat([p.grad.view(-1) for p in self.model.parameters()])\n",
    "            grads.append(g / g.norm())\n",
    "            if len(grads) >= self.mem_size:\n",
    "                break\n",
    "        if grads:\n",
    "            mean_g = torch.stack(grads).mean(0)\n",
    "            mean_g /= mean_g.norm()\n",
    "            self.S.append(mean_g)\n",
    "            if len(self.S) > self.mem_size:\n",
    "                self.S.pop(0)\n",
    "\n",
    "# === Training loop with OGD ===\n",
    "# ogd = OGD(SimpleCNN(num_classes=classes_per_task), lr=learning_rate, device=device, mem_size=mem_size)\n",
    "ogd = OGD(WideResNet(depth=28, widen_factor=10, num_classes=classes_per_task),\n",
    "          lr=learning_rate, device=device, mem_size=mem_size)\n",
    "accuracy_matrix = np.zeros((num_tasks, num_tasks))\n",
    "\n",
    "def evaluate_task(model, dataloader):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            preds = model(x).argmax(dim=1)\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += y.size(0)\n",
    "    return correct / total\n",
    "\n",
    "for task_id, train_dataset in enumerate(train_tasks):\n",
    "    print(f\"\\n=== Training Task {task_id+1} ===\")\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0.0\n",
    "        for x, y in tqdm(train_loader):\n",
    "            epoch_loss += ogd.observe(x, y)\n",
    "        print(f\"Epoch {epoch+1}, Loss={epoch_loss/len(train_loader):.4f}\")\n",
    "\n",
    "    # Evaluate on all seen tasks\n",
    "    for eval_id in range(task_id+1):\n",
    "        test_loader = DataLoader(test_tasks[eval_id], batch_size=batch_size, shuffle=False)\n",
    "        acc = evaluate_task(ogd.model, test_loader)\n",
    "        accuracy_matrix[task_id, eval_id] = acc\n",
    "        print(f\"Accuracy on Task {eval_id+1}: {acc:.3f}\")\n",
    "\n",
    "    ogd.end_task(train_loader)\n",
    "\n",
    "# === Metrics ===\n",
    "ACC = accuracy_matrix[-1].mean()\n",
    "F = np.mean([np.max(accuracy_matrix[:num_tasks-1, j]) - accuracy_matrix[-1, j] for j in range(num_tasks-1)]) if num_tasks>1 else 0.0\n",
    "BWT = np.mean([accuracy_matrix[-1, j] - accuracy_matrix[j, j] for j in range(num_tasks-1)]) if num_tasks>1 else 0.0\n",
    "FWT = np.mean([accuracy_matrix[i, i+1] for i in range(num_tasks-1)]) if num_tasks>1 else 0.0\n",
    "num_params = sum(p.numel() for p in ogd.model.parameters())\n",
    "mem_usage = len(ogd.S) * num_params * 4 / (1024**2)\n",
    "PSM = 0.5*(1-F) + 0.5*max(FWT,0)\n",
    "\n",
    "print(\"=== Metrics (Split CIFAR-10 CNN OGD) ===\")\n",
    "print(f\"ACC={ACC:.4f}, F={F:.4f}, BWT={BWT:.4f}, FWT={FWT:.4f}, Mem={mem_usage:.2f}MB, PSM={PSM:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.imshow(accuracy_matrix, cmap='viridis', interpolation='nearest')\n",
    "plt.colorbar(label='Accuracy')\n",
    "plt.xlabel('Evaluation Task')\n",
    "plt.ylabel('Training Task')\n",
    "plt.title('OGD Accuracy Matrix (Split CIFAR-10 CNN)')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
